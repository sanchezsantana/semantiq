{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285dcc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports básicos y configuración\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Para reproducibilidad global\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Cargar la OMS v2 desde YAML\n",
    "\n",
    "RUTA_OMS = \"../data/oms/99_oms_stde_v2.yaml\"\n",
    "OUTPUT_DIR = \"../data/synthetic/\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def cargar_oms(ruta_yaml: str) -> dict:\n",
    "    \"\"\"Carga la OMS (ontología mínima sintética) desde un archivo YAML.\"\"\"\n",
    "    with open(ruta_yaml, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "oms = cargar_oms(RUTA_OMS)\n",
    "\n",
    "# Vista rápida de consistencia\n",
    "print(\"ID OMS:\", oms.get(\"id_oms\"))\n",
    "print(\"Versión:\", oms.get(\"version\"))\n",
    "print(\"Nombre:\", oms.get(\"nombre\"))\n",
    "\n",
    "escenario = oms[\"escenario_operacion\"]\n",
    "print(\"ID Escenario:\", escenario.get(\"id_escenario\"))\n",
    "print(\"Fecha inicio:\", escenario[\"fecha_inicio\"])\n",
    "print(\"Número de semanas:\", escenario[\"numero_semanas\"])\n",
    "\n",
    "print(\"\\nRiesgos modelados explícitamente (ontología reducida):\")\n",
    "for r in oms[\"riesgos_modelados\"]:\n",
    "    print(\" -\", r[\"id_riesgo\"], \"→\", r[\"nombre\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c898439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Generar calendario diario para las 12 semanas del escenario\n",
    "\n",
    "DIA_SEMANA_ES = {\n",
    "    0: \"Lunes\",\n",
    "    1: \"Martes\",\n",
    "    2: \"Miércoles\",\n",
    "    3: \"Jueves\",\n",
    "    4: \"Viernes\",\n",
    "    5: \"Sábado\",\n",
    "    6: \"Domingo\",\n",
    "}\n",
    "\n",
    "\n",
    "def generar_calendario(oms: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Genera un calendario según el número de semanas definido en la OMS v2.\n",
    "    Columnas:\n",
    "        - fecha (datetime.date)\n",
    "        - semana (1..N)\n",
    "        - dia_semana (texto)\n",
    "    \"\"\"\n",
    "    esc = oms[\"escenario_operacion\"]\n",
    "    fecha_inicio = datetime.strptime(esc[\"fecha_inicio\"], \"%Y-%m-%d\")\n",
    "    n_semanas = esc[\"numero_semanas\"]\n",
    "    n_dias_total = n_semanas * 7\n",
    "\n",
    "    fechas = [fecha_inicio + timedelta(days=i) for i in range(n_dias_total)]\n",
    "    data = []\n",
    "    for i, fecha in enumerate(fechas):\n",
    "        semana = i // 7 + 1\n",
    "        dia_semana = DIA_SEMANA_ES[fecha.weekday()]\n",
    "        data.append(\n",
    "            {\n",
    "                \"fecha\": fecha.date(),\n",
    "                \"semana\": semana,\n",
    "                \"dia_semana\": dia_semana,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "calendario = generar_calendario(oms)\n",
    "\n",
    "print(\"Rango de fechas:\", calendario[\"fecha\"].min(), \"→\", calendario[\"fecha\"].max())\n",
    "print(\"Semanas únicas en calendario:\", sorted(calendario[\"semana\"].unique()))\n",
    "calendario.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ff7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Extraer áreas, roles, turnos, distribuciones y parámetros STDE\n",
    "\n",
    "escenario = oms[\"escenario_operacion\"]\n",
    "\n",
    "TURNOS = escenario[\"turnos\"]\n",
    "AREAS = escenario[\"areas_operacionales\"]\n",
    "ROLES = escenario[\"roles_clave\"]\n",
    "\n",
    "DISTRIB = oms[\"distribuciones\"]\n",
    "\n",
    "# Parámetros STDE (población base)\n",
    "params_stde = escenario.get(\"parametros_STDE\", oms.get(\"parametros_STDE\", {}))\n",
    "POBLACION_BASE = params_stde.get(\"poblacion_base_trabajadores\", 120)\n",
    "\n",
    "print(\"Turnos:\", [t[\"id_turno\"] for t in TURNOS])\n",
    "print(\"Áreas:\", [a[\"id_area\"] for a in AREAS])\n",
    "print(\"Roles (ejemplo primeros 4):\", [r[\"id_rol\"] for r in ROLES[:4]])\n",
    "print(\"Semanas definidas en distribuciones:\", list(DISTRIB.keys()))\n",
    "print(\"POBLACION_BASE:\", POBLACION_BASE)\n",
    "print(\"Unidad tasas:\", params_stde.get(\"unidad_tasas\", \"por_100_trabajadores_por_semana\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Helper para convertir \"por 100\" semanal a lambda diario (Poisson)\n",
    "\n",
    "def lambda_diario(desde_por_100_semana: float, poblacion: int = POBLACION_BASE) -> float:\n",
    "    \"\"\"\n",
    "    Convierte una tasa semanal \"por 100 trabajadores\" a una lambda diaria\n",
    "    para una distribución Poisson, según la población base.\n",
    "    \"\"\"\n",
    "    tasa_semana_real = desde_por_100_semana * (poblacion / 100.0)  # escala por población\n",
    "    return tasa_semana_real / 7.0  # asumimos distribución uniforme dentro de la semana\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2d24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Ranking proactivo 12 semanas y FDO semanales (Texto 3)\n",
    "\n",
    "# Riesgos considerados en el ranking proactivo\n",
    "RIESGOS_RANKING = [\"R01\", \"R02\", \"R03\", \"R04\", \"R05\", \"R06\", \"R07\", \"R08\", \"R09\", \"R10\"]\n",
    "\n",
    "# Tabla de ranking semanal (Semana 1 a 12) según Texto 3\n",
    "# Top 1 (más crítico) → Top 10 (menos crítico)\n",
    "RANKING_SEMANAL_RAW = {\n",
    "    1:  [\"R01\",\"R02\",\"R05\",\"R03\",\"R04\",\"R07\",\"R06\",\"R08\",\"R10\",\"R09\"],\n",
    "    2:  [\"R01\",\"R02\",\"R04\",\"R05\",\"R03\",\"R06\",\"R08\",\"R07\",\"R09\",\"R10\"],\n",
    "    3:  [\"R01\",\"R05\",\"R02\",\"R03\",\"R04\",\"R06\",\"R08\",\"R09\",\"R07\",\"R10\"],\n",
    "    4:  [\"R03\",\"R05\",\"R01\",\"R04\",\"R02\",\"R06\",\"R08\",\"R07\",\"R10\",\"R09\"],\n",
    "    5:  [\"R01\",\"R03\",\"R05\",\"R02\",\"R04\",\"R07\",\"R06\",\"R10\",\"R08\",\"R09\"],\n",
    "    6:  [\"R03\",\"R01\",\"R02\",\"R05\",\"R04\",\"R08\",\"R06\",\"R07\",\"R09\",\"R10\"],\n",
    "    7:  [\"R03\",\"R02\",\"R04\",\"R01\",\"R05\",\"R06\",\"R08\",\"R07\",\"R10\",\"R09\"],\n",
    "    8:  [\"R05\",\"R03\",\"R02\",\"R04\",\"R01\",\"R08\",\"R06\",\"R10\",\"R07\",\"R09\"],\n",
    "    9:  [\"R05\",\"R04\",\"R03\",\"R02\",\"R06\",\"R01\",\"R07\",\"R10\",\"R09\",\"R08\"],\n",
    "    10: [\"R04\",\"R05\",\"R03\",\"R02\",\"R01\",\"R08\",\"R06\",\"R09\",\"R10\",\"R07\"],\n",
    "    11: [\"R05\",\"R04\",\"R02\",\"R01\",\"R06\",\"R03\",\"R08\",\"R09\",\"R10\",\"R07\"],\n",
    "    12: [\"R05\",\"R02\",\"R04\",\"R01\",\"R03\",\"R06\",\"R08\",\"R10\",\"R07\",\"R09\"], \n",
    "}\n",
    "\n",
    "\n",
    "# Construimos DataFrame en formato largo: (semana, posicion, id_riesgo)\n",
    "ranking_rows = []\n",
    "for semana, lista_riesgos in RANKING_SEMANAL_RAW.items():\n",
    "    for pos, r in enumerate(lista_riesgos, start=1):\n",
    "        ranking_rows.append({\"semana\": semana, \"posicion\": pos, \"id_riesgo\": r})\n",
    "\n",
    "df_ranking_proactivo = pd.DataFrame(ranking_rows)\n",
    "df_ranking_proactivo.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6b: FDO semanales base (Texto 3) + FDO del lunes crítico\n",
    "\n",
    "# Tabla de patrones semanales (promedio base, antes de ruido)\n",
    "# Orden mapeado 1..12 a:\n",
    "#  1: 1 Nov\n",
    "#  2: 2 Nov\n",
    "#  3: 3 Nov\n",
    "#  4: 4 Nov\n",
    "#  5: 1 Dic\n",
    "#  6: 2 Dic\n",
    "#  7: 3 Dic\n",
    "#  8: Navidad\n",
    "#  9: Año Nuevo\n",
    "# 10: 1 Ene\n",
    "# 11: 2 Ene\n",
    "# 12: 3 Ene\n",
    "FDO_SEMANA_BASE = {\n",
    "    1:  {\"clima\": 45, \"fatiga\": 40, \"congestion\": 40, \"backlog\": 45, \"dotacion\": 80, \"variabilidad\": 20},\n",
    "    2:  {\"clima\": 50, \"fatiga\": 42, \"congestion\": 45, \"backlog\": 50, \"dotacion\": 78, \"variabilidad\": 22},\n",
    "    3:  {\"clima\": 55, \"fatiga\": 45, \"congestion\": 50, \"backlog\": 55, \"dotacion\": 77, \"variabilidad\": 25},\n",
    "    4:  {\"clima\": 60, \"fatiga\": 48, \"congestion\": 55, \"backlog\": 60, \"dotacion\": 76, \"variabilidad\": 28},\n",
    "    5:  {\"clima\": 65, \"fatiga\": 55, \"congestion\": 65, \"backlog\": 70, \"dotacion\": 72, \"variabilidad\": 32},\n",
    "    6:  {\"clima\": 70, \"fatiga\": 58, \"congestion\": 70, \"backlog\": 75, \"dotacion\": 70, \"variabilidad\": 35},\n",
    "    7:  {\"clima\": 72, \"fatiga\": 60, \"congestion\": 75, \"backlog\": 78, \"dotacion\": 68, \"variabilidad\": 38},\n",
    "    8:  {\"clima\": 60, \"fatiga\": 40, \"congestion\": 40, \"backlog\": 65, \"dotacion\": 65, \"variabilidad\": 40},\n",
    "    9:  {\"clima\": 62, \"fatiga\": 35, \"congestion\": 38, \"backlog\": 68, \"dotacion\": 64, \"variabilidad\": 45},\n",
    "    10: {\"clima\": 75, \"fatiga\": 55, \"congestion\": 75, \"backlog\": 80, \"dotacion\": 60, \"variabilidad\": 55},\n",
    "    11: {\"clima\": 78, \"fatiga\": 58, \"congestion\": 80, \"backlog\": 85, \"dotacion\": 58, \"variabilidad\": 60},\n",
    "    12: {\"clima\": 80, \"fatiga\": 60, \"congestion\": 82, \"backlog\": 90, \"dotacion\": 55, \"variabilidad\": 65},\n",
    "}\n",
    "\n",
    "# FDO especial del lunes crítico (primera semana de febrero, fuera del horizonte 12s)\n",
    "FDO_LUNES_CRITICO = {\n",
    "    \"clima\": 88,\n",
    "    \"fatiga\": 75,\n",
    "    \"congestion\": 90,\n",
    "    \"backlog\": 95,\n",
    "    \"dotacion\": 50,\n",
    "    \"variabilidad\": 78,\n",
    "}\n",
    "\n",
    "def fdo_base_por_semana(semana: int) -> dict:\n",
    "    \"\"\"Devuelve el FDO base (sin ruido) para una semana 1..12.\"\"\"\n",
    "    return FDO_SEMANA_BASE[semana]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17dd7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6c: Generar criticidad continua (thresholds 0–1) a partir del ranking v4.4\n",
    "\n",
    "def generar_thresholds_continuos(df_ranking: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Para cada semana y cada riesgo asigna un valor continuo de criticidad en 0–1.\n",
    "    Reglas:\n",
    "        - Top1 siempre entre 0.90–1.00\n",
    "        - Top10 entre 0.10–0.20\n",
    "        - Curva decreciente no lineal (más peso a los primeros lugares)\n",
    "        - Independiente semana a semana (como el modelo real)\n",
    "    \"\"\"\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    # Parámetros de distribución continua\n",
    "    top_min = 0.90\n",
    "    top_max = 1.00\n",
    "    low_min = 0.10\n",
    "    low_max = 0.20\n",
    "\n",
    "    for semana in sorted(df_ranking[\"semana\"].unique()):\n",
    "        df_sem = df_ranking[df_ranking[\"semana\"] == semana].sort_values(\"posicion\")\n",
    "        n = len(df_sem)\n",
    "\n",
    "        # curvas suaves: exponencial negativa\n",
    "        posiciones = df_sem[\"posicion\"].values\n",
    "        base = np.exp(-0.35 * (posiciones - 1))      # 1.0, 0.70, 0.49, ...\n",
    "        base_norm = (base - base.min()) / (base.max() - base.min())\n",
    "\n",
    "        # escalamiento a rango 0.10–1.00\n",
    "        criticidades = low_min + base_norm * (top_max - low_min)\n",
    "\n",
    "        for (_, row), crit in zip(df_sem.iterrows(), criticidades):\n",
    "            registros.append({\n",
    "                \"semana\": semana,\n",
    "                \"id_riesgo\": row[\"id_riesgo\"],\n",
    "                \"posicion_ranking\": row[\"posicion\"],\n",
    "                \"criticidad_continua\": round(float(crit), 4)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(registros)\n",
    "\n",
    "\n",
    "df_thresholds = generar_thresholds_continuos(df_ranking_proactivo)\n",
    "df_thresholds.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd06d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Generación de observaciones sintéticas (12 semanas)\n",
    "\n",
    "def generar_observaciones(oms: dict, calendario: pd.DataFrame) -> pd.DataFrame:\n",
    "    stde_obs_cfg = oms[\"stde\"][\"observaciones\"]\n",
    "    tipos_validos = stde_obs_cfg[\"tipo_observaciones_validos\"]\n",
    "    distrib = oms[\"distribuciones\"]\n",
    "\n",
    "    # Map de tipos (ej. {\"OPG\": \"Observación Preventiva de Gestión\", ...})\n",
    "    tipos_map = {t[\"codigo\"]: t[\"nombre\"] for t in tipos_validos}\n",
    "\n",
    "    registros = []\n",
    "    contador_obs = 1\n",
    "\n",
    "    for _, row in calendario.iterrows():\n",
    "        fecha = row[\"fecha\"]\n",
    "        semana = int(row[\"semana\"])\n",
    "        dia_semana = row[\"dia_semana\"]\n",
    "\n",
    "        sem_key = f\"semana_{semana}\"\n",
    "        sem_cfg = distrib[sem_key]\n",
    "        obs_por_100 = sem_cfg[\"observaciones_por_100\"]\n",
    "\n",
    "        # Para cada tipo (OPG, OCC) calculamos λ diario (Poisson)\n",
    "        for tipo, tasa_semana_100 in obs_por_100.items():\n",
    "            base_lambda = lambda_diario(tasa_semana_100, POBLACION_BASE)\n",
    "\n",
    "            n_obs = np.random.poisson(base_lambda)\n",
    "            if n_obs <= 0:\n",
    "                continue\n",
    "\n",
    "            # Distribuimos las observaciones entre turnos, áreas y roles\n",
    "            for _ in range(n_obs):\n",
    "                turno = random.choice(TURNOS)[\"id_turno\"]\n",
    "                area = random.choice(AREAS)[\"id_area\"]\n",
    "                rol = random.choice(ROLES)[\"id_rol\"]\n",
    "\n",
    "                registros.append(\n",
    "                    {\n",
    "                        \"id_observacion\": f\"OBS_{contador_obs:06d}\",\n",
    "                        \"fecha\": fecha,\n",
    "                        \"semana\": semana,\n",
    "                        \"dia_semana\": dia_semana,\n",
    "                        \"turno\": turno,\n",
    "                        \"id_area\": area,\n",
    "                        \"id_rol\": rol,\n",
    "                        \"tipo_observacion\": tipo,\n",
    "                        \"descripcion_observacion\": f\"Observación sintética tipo {tipos_map[tipo]}\",\n",
    "                        \"accion_inmediata\": \"Acción sintética registrada.\",\n",
    "                    }\n",
    "                )\n",
    "                contador_obs += 1\n",
    "\n",
    "    df_obs = pd.DataFrame(registros)\n",
    "    return df_obs\n",
    "\n",
    "\n",
    "df_observaciones = generar_observaciones(oms, calendario)\n",
    "print(\"Total observaciones generadas:\", len(df_observaciones))\n",
    "df_observaciones.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09924440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Helpers de severidad para incidentes\n",
    "\n",
    "def con_lesion_por_tipo(tipo_incidente: str) -> bool:\n",
    "    \"\"\"\n",
    "    IMAY, IMED, ILEV => con lesión; INMI => sin lesión.\n",
    "    \"\"\"\n",
    "    return tipo_incidente in (\"IMAY\", \"IMED\", \"ILEV\")\n",
    "\n",
    "\n",
    "def dias_perdidos_por_tipo(tipo_incidente: str) -> int:\n",
    "    \"\"\"\n",
    "    Lógica sintética simple para días perdidos según tipo de incidente.\n",
    "    \"\"\"\n",
    "    if tipo_incidente == \"IMAY\":\n",
    "        return max(0, int(np.random.poisson(15)) + 5)\n",
    "    if tipo_incidente == \"IMED\":\n",
    "        return max(0, int(np.random.poisson(5)) + 1)\n",
    "    if tipo_incidente == \"ILEV\":\n",
    "        return max(0, int(np.random.poisson(1)))\n",
    "    # INMI: sin lesión => 0 días\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadb34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Generación de incidentes sintéticos (12 semanas)\n",
    "\n",
    "def generar_incidentes(oms: dict, calendario: pd.DataFrame) -> pd.DataFrame:\n",
    "    stde_inc_cfg = oms[\"stde\"][\"incidentes\"]\n",
    "    tipos_validos = stde_inc_cfg[\"tipos_incidentes_validos\"]\n",
    "    distrib = oms[\"distribuciones\"]\n",
    "\n",
    "    tipos_map = {t[\"codigo\"]: t[\"nombre\"] for t in tipos_validos}\n",
    "\n",
    "    registros = []\n",
    "    contador_inc = 1\n",
    "\n",
    "    for _, row in calendario.iterrows():\n",
    "        fecha = row[\"fecha\"]\n",
    "        semana = int(row[\"semana\"])\n",
    "        dia_semana = row[\"dia_semana\"]\n",
    "\n",
    "        sem_key = f\"semana_{semana}\"\n",
    "        sem_cfg = distrib[sem_key]\n",
    "        inc_por_100 = sem_cfg[\"incidentes_por_100\"]\n",
    "\n",
    "        for tipo, tasa_semana_100 in inc_por_100.items():\n",
    "            base_lambda = lambda_diario(tasa_semana_100, POBLACION_BASE)\n",
    "            lam = base_lambda  # ya no aplicamos \"lunes crítico\" dentro de las 12 semanas\n",
    "\n",
    "            n_inc = np.random.poisson(lam)\n",
    "            if n_inc <= 0:\n",
    "                continue\n",
    "\n",
    "            for _ in range(n_inc):\n",
    "                turno = random.choice(TURNOS)[\"id_turno\"]\n",
    "                area = random.choice(AREAS)[\"id_area\"]\n",
    "                rol = random.choice(ROLES)[\"id_rol\"]\n",
    "\n",
    "                con_les = con_lesion_por_tipo(tipo)\n",
    "                dias_perdidos = dias_perdidos_por_tipo(tipo) if con_les else 0\n",
    "\n",
    "                registros.append(\n",
    "                    {\n",
    "                        \"id_incidente\": f\"INC_{contador_inc:06d}\",\n",
    "                        \"fecha\": fecha,\n",
    "                        \"semana\": semana,\n",
    "                        \"dia_semana\": dia_semana,\n",
    "                        \"turno\": turno,\n",
    "                        \"id_area\": area,\n",
    "                        \"id_rol\": rol,\n",
    "                        \"tipo_incidente\": tipo,\n",
    "                        \"descripcion_incidente\": f\"Incidente sintético tipo {tipos_map[tipo]}\",\n",
    "                        \"con_lesion\": con_les,\n",
    "                        \"dias_perdidos\": dias_perdidos,\n",
    "                    }\n",
    "                )\n",
    "                contador_inc += 1\n",
    "\n",
    "    df_inc = pd.DataFrame(registros)\n",
    "    return df_inc\n",
    "\n",
    "\n",
    "df_incidentes = generar_incidentes(oms, calendario)\n",
    "print(\"Total incidentes generados:\", len(df_incidentes))\n",
    "df_incidentes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231db9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Generación de auditorías sintéticas (12 semanas)\n",
    "\n",
    "def generar_auditorias(oms: dict, calendario: pd.DataFrame) -> pd.DataFrame:\n",
    "    stde_aud_cfg = oms[\"stde\"][\"auditorias\"]\n",
    "    tipos_validos = stde_aud_cfg[\"tipos_auditoria_validos\"]\n",
    "    distrib = oms[\"distribuciones\"]\n",
    "\n",
    "    tipos_map = {t[\"codigo\"]: t[\"nombre\"] for t in tipos_validos}\n",
    "    registros = []\n",
    "    contador_aud = 1\n",
    "\n",
    "    for _, row in calendario.iterrows():\n",
    "        fecha = row[\"fecha\"]\n",
    "        semana = int(row[\"semana\"])\n",
    "        dia_semana = row[\"dia_semana\"]\n",
    "\n",
    "        sem_key = f\"semana_{semana}\"\n",
    "        sem_cfg = distrib[sem_key]\n",
    "        aud_por_100 = sem_cfg[\"auditorias_por_100\"]\n",
    "\n",
    "        # λ diarios por tipo de auditoría\n",
    "        lambdas = {\n",
    "            tipo: lambda_diario(tasa_semana_100, POBLACION_BASE)\n",
    "            for tipo, tasa_semana_100 in aud_por_100.items()\n",
    "        }\n",
    "\n",
    "        for tipo, lam in lambdas.items():\n",
    "            n_aud = np.random.poisson(lam)\n",
    "            if n_aud <= 0:\n",
    "                continue\n",
    "\n",
    "            for _ in range(n_aud):\n",
    "                turno = random.choice(TURNOS)[\"id_turno\"]\n",
    "                area = random.choice(AREAS)[\"id_area\"]\n",
    "\n",
    "                if tipo == \"AUC\":\n",
    "                    resultado = \"Cumple requisitos revisados.\"\n",
    "                    hallazgos = \"Sin hallazgos críticos; observaciones menores.\"\n",
    "                else:  # AUF\n",
    "                    resultado = \"No cumple todos los requisitos.\"\n",
    "                    hallazgos = \"Se identifican desviaciones relevantes.\"\n",
    "\n",
    "                registros.append(\n",
    "                    {\n",
    "                        \"id_auditoria\": f\"AUD_{contador_aud:06d}\",\n",
    "                        \"fecha\": fecha,\n",
    "                        \"semana\": semana,\n",
    "                        \"dia_semana\": dia_semana,\n",
    "                        \"turno\": turno,\n",
    "                        \"id_area\": area,\n",
    "                        \"tipo_auditoria\": tipo,\n",
    "                        \"resultado\": resultado,\n",
    "                        \"hallazgos_clave\": hallazgos,\n",
    "                    }\n",
    "                )\n",
    "                contador_aud += 1\n",
    "\n",
    "    df_aud = pd.DataFrame(registros)\n",
    "    return df_aud\n",
    "\n",
    "\n",
    "df_auditorias = generar_auditorias(oms, calendario)\n",
    "print(\"Total auditorías generadas:\", len(df_auditorias))\n",
    "df_auditorias.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Generar FDO diario para las 12 semanas\n",
    "\n",
    "def generar_fdo_diario(calendario: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Genera FDO diarios a partir de los valores promedio semanales FDO_SEMANA_BASE.\n",
    "    Se añade un ruido suave para evitar series completamente planas dentro de la semana.\n",
    "    \"\"\"\n",
    "    registros = []\n",
    "\n",
    "    for _, row in calendario.iterrows():\n",
    "        fecha = row[\"fecha\"]\n",
    "        semana = int(row[\"semana\"])\n",
    "        dia_semana = row[\"dia_semana\"]\n",
    "\n",
    "        base = fdo_base_por_semana(semana)\n",
    "\n",
    "        # Ruido suave (puedes ajustar sigma si quieres más variación)\n",
    "        def noisy(x, sigma=2.0):\n",
    "            return float(np.clip(np.random.normal(x, sigma), 0, 100))\n",
    "\n",
    "        registros.append(\n",
    "            {\n",
    "                \"fecha\": fecha,\n",
    "                \"semana\": semana,\n",
    "                \"dia_semana\": dia_semana,\n",
    "                \"clima\": noisy(base[\"clima\"]),\n",
    "                \"fatiga\": noisy(base[\"fatiga\"]),\n",
    "                \"congestion\": noisy(base[\"congestion\"]),\n",
    "                \"backlog\": noisy(base[\"backlog\"]),\n",
    "                \"dotacion\": noisy(base[\"dotacion\"]),\n",
    "                \"variabilidad\": noisy(base[\"variabilidad\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df_fdo = pd.DataFrame(registros)\n",
    "    return df_fdo\n",
    "\n",
    "\n",
    "df_fdo_diario = generar_fdo_diario(calendario)\n",
    "print(\"Total registros FDO diarios:\", len(df_fdo_diario))\n",
    "df_fdo_diario.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Evento del lunes crítico (R01 salta 72 → 96, modelo proactivo rezagado)\n",
    "\n",
    "def generar_evento_lunes_critico(oms: dict, df_ranking: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Genera un pequeño dataset para el evento del lunes crítico,\n",
    "    donde R01 tiene un salto de criticidad real 72 → 96,\n",
    "    pero el modelo proactivo sigue usando el ranking #12 (domingo anterior).\n",
    "    \"\"\"\n",
    "    fecha_lc_str = oms[\"escenario_operacion\"][\"lunes_critico\"][\"fecha\"]\n",
    "    fecha_lc = datetime.strptime(fecha_lc_str, \"%Y-%m-%d\").date()\n",
    "\n",
    "    # Posición de R01 en el ranking de la semana 12 (ranking #12 del domingo anterior)\n",
    "    semana_ref = 12\n",
    "    pos_R01_sem12 = int(\n",
    "        df_ranking[\n",
    "            (df_ranking[\"semana\"] == semana_ref) & (df_ranking[\"id_riesgo\"] == \"R01\")\n",
    "        ][\"posicion\"].iloc[0]\n",
    "    )\n",
    "\n",
    "    # Valores de criticidad sintéticos coherentes con el Texto 3 (72 → 96)\n",
    "    criticidad_real_sem12 = 72\n",
    "    criticidad_real_lunes_critico = 96\n",
    "\n",
    "    # FDO del lunes crítico (extra, fuera del horizonte de 12 semanas)\n",
    "    fdo_lc = FDO_LUNES_CRITICO.copy()\n",
    "\n",
    "    registro = {\n",
    "        \"fecha_lunes_critico\": fecha_lc,\n",
    "        \"id_riesgo\": \"R01\",\n",
    "        \"criticidad_real_sem12\": criticidad_real_sem12,\n",
    "        \"criticidad_real_lunes_critico\": criticidad_real_lunes_critico,\n",
    "        \"posicion_proactivo_sem12\": pos_R01_sem12,\n",
    "        \"nota_modelo\": (\n",
    "            \"El modelo proactivo sigue usando el ranking #12 (domingo anterior), \"\n",
    "            \"sin incorporar todavía el salto de criticidad de R01 observado el lunes crítico.\"\n",
    "        ),\n",
    "        \"fdo_clima\": fdo_lc[\"clima\"],\n",
    "        \"fdo_fatiga\": fdo_lc[\"fatiga\"],\n",
    "        \"fdo_congestion\": fdo_lc[\"congestion\"],\n",
    "        \"fdo_backlog\": fdo_lc[\"backlog\"],\n",
    "        \"fdo_dotacion\": fdo_lc[\"dotacion\"],\n",
    "        \"fdo_variabilidad\": fdo_lc[\"variabilidad\"],\n",
    "    }\n",
    "\n",
    "    df_lunes_critico = pd.DataFrame([registro])\n",
    "    return df_lunes_critico\n",
    "\n",
    "\n",
    "df_lunes_critico = generar_evento_lunes_critico(oms, df_ranking_proactivo)\n",
    "df_lunes_critico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962dabcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Guardar CSV y mostrar resúmenes rápidos\n",
    "\n",
    "ruta_obs = os.path.join(OUTPUT_DIR, \"stde_observaciones_12s.csv\")\n",
    "ruta_inc = os.path.join(OUTPUT_DIR, \"stde_incidentes_12s.csv\")\n",
    "ruta_aud = os.path.join(OUTPUT_DIR, \"stde_auditorias_12s.csv\")\n",
    "ruta_rank = os.path.join(OUTPUT_DIR, \"stde_ranking_proactivo_12s.csv\")\n",
    "ruta_rank_scores = os.path.join(OUTPUT_DIR, \"stde_ranking_proactivo_scores_12s.csv\")\n",
    "ruta_fdo = os.path.join(OUTPUT_DIR, \"stde_fdo_diario_12s.csv\")\n",
    "ruta_lc = os.path.join(OUTPUT_DIR, \"stde_riesgos_evento_lunes_critico.csv\")\n",
    "ruta_thr = os.path.join(OUTPUT_DIR, \"stde_ranking_thresholds_12s.csv\")\n",
    "\n",
    "\n",
    "df_observaciones.to_csv(ruta_obs, index=False, encoding=\"utf-8\")\n",
    "df_incidentes.to_csv(ruta_inc, index=False, encoding=\"utf-8\")\n",
    "df_auditorias.to_csv(ruta_aud, index=False, encoding=\"utf-8\")\n",
    "df_ranking_proactivo.to_csv(ruta_rank, index=False, encoding=\"utf-8\")\n",
    "df_riesgos_scores.to_csv(ruta_rank_scores, index=False, encoding=\"utf-8\")\n",
    "df_fdo_diario.to_csv(ruta_fdo, index=False, encoding=\"utf-8\")\n",
    "df_lunes_critico.to_csv(ruta_lc, index=False, encoding=\"utf-8\")\n",
    "df_thresholds.to_csv(ruta_thr, index=False, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "print(\"Archivos guardados:\")\n",
    "print(\" -\", ruta_obs)\n",
    "print(\" -\", ruta_inc)\n",
    "print(\" -\", ruta_aud)\n",
    "print(\" -\", ruta_rank)\n",
    "print(\" -\", ruta_rank_scores)\n",
    "print(\" -\", ruta_fdo)\n",
    "print(\" -\", ruta_lc)\n",
    "print(\" -\", ruta_thr)\n",
    "\n",
    "\n",
    "print(\"\\nResumen por semana - Observaciones:\")\n",
    "print(df_observaciones.groupby(\"semana\")[\"id_observacion\"].count())\n",
    "\n",
    "print(\"\\nResumen por semana - Incidentes:\")\n",
    "print(df_incidentes.groupby(\"semana\")[\"id_incidente\"].count())\n",
    "\n",
    "print(\"\\nResumen por semana - Auditorías:\")\n",
    "print(df_auditorias.groupby(\"semana\")[\"id_auditoria\"].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ccd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Validaciones rápidas de consistencia\n",
    "\n",
    "print(\"Semanas calendario:\", sorted(calendario['semana'].unique()))\n",
    "print(\"Semanas en distribuciones YAML:\", sorted(int(k.split('_')[1]) for k in DISTRIB.keys()))\n",
    "\n",
    "print(\"\\nRanking proactivo - posiciones R01, R02, R03 por semana:\")\n",
    "pivot_r = df_ranking_proactivo.pivot_table(\n",
    "    index=\"semana\", columns=\"id_riesgo\", values=\"posicion\"\n",
    ")\n",
    "print(pivot_r[[\"R01\", \"R02\", \"R03\"]])\n",
    "\n",
    "print(\"\\nFDO promedio por semana (a partir del diario):\")\n",
    "cols_fdo = [\"clima\", \"fatiga\", \"congestion\", \"backlog\", \"dotacion\", \"variabilidad\"]\n",
    "print(df_fdo_diario.groupby(\"semana\")[cols_fdo].mean().round(1))\n",
    "\n",
    "print(\"\\nEvento lunes crítico:\")\n",
    "print(df_lunes_critico)\n",
    "\n",
    "print(\"\\nThresholds promedio por semana:\")\n",
    "print(df_thresholds.pivot_table(index=\"semana\", values=\"criticidad_continua\", aggfunc=\"mean\").round(3))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k9_mining_safety",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
