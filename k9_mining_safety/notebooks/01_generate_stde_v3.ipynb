{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "703ef0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 0.1 ‚Äì Imports y configuraci√≥n de paths correctos\n",
    "\n",
    "import os\n",
    "import random\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Rutas REALES seg√∫n tu proyecto:\n",
    "# notebooks/\n",
    "#   ‚îî‚îÄ‚îÄ 01_generate_stde_v3.ipynb\n",
    "# data/\n",
    "#     ‚îú‚îÄ‚îÄ oms/\n",
    "#     ‚îú‚îÄ‚îÄ ontology/\n",
    "#     ‚îî‚îÄ‚îÄ synthetic/\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "RUTA_OMS = \"../data/oms/99_oms_stde_v3.yaml\"\n",
    "\n",
    "# Cat√°logos en ontology/\n",
    "PATH_ROLES     = \"../data/ontology/10_catalogo_roles_v3.yaml\"\n",
    "PATH_TAREAS    = \"../data/ontology/12_catalogo_tareas_v1.yaml\"\n",
    "PATH_AREAS     = \"../data/ontology/13_catalogo_areas_operacionales_v1.yaml\"\n",
    "PATH_RIESGOS   = \"../data/ontology/01_catalogo_riesgos_v8.yaml\"\n",
    "PATH_CONTROLES = \"../data/ontology/02_catalogo_controles_v6.yaml\"\n",
    "\n",
    "# Modelo proactivo en oms/\n",
    "PATH_PROACTIVO = \"../data/oms/stde_proactivo_semanal_v4_4.csv\"\n",
    "\n",
    "# Directorio de salida (synthetic/)\n",
    "OUTPUT_DIR = \"../data/synthetic/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Configuraci√≥n de aleatoriedad\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 0.2 ‚Äì Cargar OMS v3\n",
    "\n",
    "def cargar_yaml(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "oms = cargar_yaml(RUTA_OMS)\n",
    "\n",
    "# Accesos r√°pidos a secciones relevantes de la OMS v3\n",
    "meta = oms.get(\"meta\", {})\n",
    "stde_cfg = oms.get(\"stde\", {})\n",
    "fdo_cfg = oms.get(\"fdo\", {})\n",
    "escenario_cfg = oms.get(\"escenario_operacion\", {})\n",
    "mapeos_operacionales = oms.get(\"mapeos_operacionales\", {})\n",
    "proactivo_cfg = oms.get(\"proactivo\", {})\n",
    "\n",
    "lunes_critico_cfg = escenario_cfg.get(\"lunes_critico\", {})\n",
    "eventos_lunes_critico = lunes_critico_cfg.get(\"eventos_sinteticos\", [])\n",
    "\n",
    "print(\"Versi√≥n OMS:\", meta.get(\"version\"))\n",
    "print(\"Fecha inicio escenario:\", escenario_cfg.get(\"fecha_inicio\"))\n",
    "print(\"N√∫mero de semanas:\", escenario_cfg.get(\"numero_semanas\"))\n",
    "print(\"Eventos del lunes cr√≠tico:\", len(eventos_lunes_critico))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 0.3 ‚Äì Cargar cat√°logos de ontolog√≠a (roles, tareas, √°reas, riesgos, controles)\n",
    "\n",
    "# Celda 0.3 ‚Äì Cargar cat√°logos oficiales (funci√≥n √∫nica)\n",
    "\n",
    "def cargar_catalogo(path):\n",
    "    \"\"\"\n",
    "    Carga cat√°logos YAML que pueden estar en dos formatos:\n",
    "    1) Una lista directamente en la ra√≠z.\n",
    "    2) Un diccionario cuya primera clave contiene una lista.\n",
    "\n",
    "    Retorna siempre un DataFrame.\n",
    "    \"\"\"\n",
    "    data = cargar_yaml(path)\n",
    "\n",
    "    # Caso 1: El archivo es directamente una lista\n",
    "    if isinstance(data, list):\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    # Caso 2: El archivo es un diccionario con una lista dentro\n",
    "    if isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            if isinstance(v, list):\n",
    "                return pd.DataFrame(v)\n",
    "\n",
    "    raise ValueError(f\"Formato no reconocido en cat√°logo: {path}\")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# CARGA DE CAT√ÅLOGOS\n",
    "# ======================\n",
    "\n",
    "df_roles     = cargar_catalogo(PATH_ROLES)\n",
    "df_tareas    = cargar_catalogo(PATH_TAREAS)\n",
    "df_areas     = cargar_catalogo(PATH_AREAS)\n",
    "df_riesgos   = cargar_catalogo(PATH_RIESGOS)\n",
    "df_controles = cargar_catalogo(PATH_CONTROLES)\n",
    "\n",
    "print(\"Cat√°logos cargados correctamente:\")\n",
    "print(\"Roles:\", df_roles.shape)\n",
    "print(\"Tareas:\", df_tareas.shape)\n",
    "print(\"√Åreas:\", df_areas.shape)\n",
    "print(\"Riesgos:\", df_riesgos.shape)\n",
    "print(\"Controles:\", df_controles.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ed7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1.1 ‚Äì Generar calendario diario del escenario STDE (12 semanas) + marca de lunes cr√≠tico\n",
    "\n",
    "def generar_calendario(escenario_cfg):\n",
    "    fecha_inicio_str = escenario_cfg[\"fecha_inicio\"]\n",
    "    numero_semanas = escenario_cfg[\"numero_semanas\"]\n",
    "    fecha_lunes_critico_str = escenario_cfg[\"lunes_critico\"][\"fecha\"]\n",
    "\n",
    "    fecha_inicio = date.fromisoformat(fecha_inicio_str)\n",
    "    dias_totales = numero_semanas * 7  # 12 semanas ‚Üí 84 d√≠as (sin lunes cr√≠tico)\n",
    "    fecha_lunes_critico = date.fromisoformat(fecha_lunes_critico_str)\n",
    "\n",
    "    registros = []\n",
    "    for i in range(dias_totales):\n",
    "        fecha = fecha_inicio + timedelta(days=i)\n",
    "        semana = (i // 7) + 1  # semana 1..12\n",
    "        dia_semana = fecha.weekday()  # 0 = lunes, 6 = domingo\n",
    "\n",
    "        registros.append(\n",
    "            {\n",
    "                \"id_dia\": i + 1,\n",
    "                \"fecha\": fecha,\n",
    "                \"semana\": semana,\n",
    "                \"dia_semana\": dia_semana,\n",
    "                \"es_lunes_critico\": (fecha == fecha_lunes_critico),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    calendario = pd.DataFrame(registros)\n",
    "    return calendario\n",
    "\n",
    "calendario = generar_calendario(escenario_cfg)\n",
    "print(\"D√≠as calendario:\", len(calendario))\n",
    "calendario.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0514fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1.2 ‚Äì Generar FDO diario (7 factores) con patrones suaves\n",
    "\n",
    "fdo_factores = fdo_cfg.get(\"factores\", [])\n",
    "\n",
    "# Creamos un √≠ndice de factores por id para referencia si se requiere despu√©s\n",
    "FDO_IDS = [f[\"id\"] for f in fdo_factores]\n",
    "\n",
    "def generar_fdo_diario(calendario):\n",
    "    registros = []\n",
    "    for _, row in calendario.iterrows():\n",
    "        fecha = row[\"fecha\"]\n",
    "        semana = row[\"semana\"]\n",
    "        id_dia = row[\"id_dia\"]\n",
    "\n",
    "        # Base de variaci√≥n semanal: degradaci√≥n leve hacia semana 12\n",
    "        # Normalizamos semana 1..12 a 0..1\n",
    "        t = (semana - 1) / (calendario[\"semana\"].max() - 1)\n",
    "\n",
    "        # Definimos patrones simplificados coherentes con la narrativa:\n",
    "        # - Producci√≥n: crece con el tiempo (m√°s presi√≥n)\n",
    "        # - Backlog: crece (mantenimiento atrasado)\n",
    "        # - Congesti√≥n: crece con producci√≥n\n",
    "        # - Fatiga: crece, modulada por d√≠a de la semana (m√°s alta al final de la semana)\n",
    "        # - Clima: variaci√≥n aleatoria suave\n",
    "        # - Dotaci√≥n: algo decreciente (baja levemente)\n",
    "        # - Variabilidad: aumenta moderadamente\n",
    "        dow = row[\"dia_semana\"]  # 0 lunes, 6 domingo\n",
    "\n",
    "        fdo_produccion = np.clip(0.3 + 0.6 * t + np.random.normal(0, 0.05), 0.0, 1.0)\n",
    "        fdo_backlog = np.clip(0.2 + 0.7 * t + np.random.normal(0, 0.05), 0.0, 1.0)\n",
    "        fdo_congestion = np.clip(0.25 + 0.6 * t + np.random.normal(0, 0.05), 0.0, 1.0)\n",
    "\n",
    "        # Fatiga: m√°s alta jueves-viernes (3,4)\n",
    "        fatiga_semana = 0.2 + 0.6 * t\n",
    "        ajuste_dow = 0.1 if dow in (3, 4) else 0.0\n",
    "        fdo_fatiga = np.clip(fatiga_semana + ajuste_dow + np.random.normal(0, 0.05), 0.0, 1.0)\n",
    "\n",
    "        # Clima: ruido con tendencia leve\n",
    "        fdo_clima = np.clip(0.4 + 0.2 * np.sin(2 * np.pi * t) + np.random.normal(0, 0.1), 0.0, 1.0)\n",
    "\n",
    "        # Dotaci√≥n: leve ca√≠da con el tiempo (renuncias, licencias, etc.)\n",
    "        fdo_dotacion = np.clip(0.9 - 0.3 * t + np.random.normal(0, 0.05), 0.0, 1.0)\n",
    "\n",
    "        # Variabilidad: aumenta hacia el final (m√°s cambios de plan)\n",
    "        fdo_variabilidad = np.clip(0.2 + 0.6 * t + np.random.normal(0, 0.05), 0.0, 1.0)\n",
    "\n",
    "        registros.append(\n",
    "            {\n",
    "                \"id_dia\": id_dia,\n",
    "                \"fecha\": fecha,\n",
    "                \"semana\": semana,\n",
    "                \"fdo_produccion\": fdo_produccion,\n",
    "                \"fdo_backlog\": fdo_backlog,\n",
    "                \"fdo_congestion\": fdo_congestion,\n",
    "                \"fdo_fatiga\": fdo_fatiga,\n",
    "                \"fdo_clima\": fdo_clima,\n",
    "                \"fdo_dotacion\": fdo_dotacion,\n",
    "                \"fdo_variabilidad\": fdo_variabilidad,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df_fdo = pd.DataFrame(registros)\n",
    "    return df_fdo\n",
    "\n",
    "df_fdo_diario = generar_fdo_diario(calendario)\n",
    "print(\"FDO diario generado:\", df_fdo_diario.shape)\n",
    "df_fdo_diario.head()\n",
    "df_fdo = df_fdo_diario.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c35b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2.1 ‚Äì Generar trayectorias diarias de criticidad para R01, R02, R03\n",
    "\n",
    "RIESGOS_FOCO = [\"R01\", \"R02\", \"R03\"]\n",
    "\n",
    "def generar_trayectorias_riesgo(calendario):\n",
    "    registros = []\n",
    "    max_semana = calendario[\"semana\"].max()\n",
    "\n",
    "    for _, row in calendario.iterrows():\n",
    "        fecha = row[\"fecha\"]\n",
    "        semana = row[\"semana\"]\n",
    "        id_dia = row[\"id_dia\"]\n",
    "\n",
    "        # Normalizaci√≥n temporal 0..1 sobre las 12 semanas\n",
    "        t = (semana - 1) / (max_semana - 1)\n",
    "\n",
    "        # -------------------------------\n",
    "        # R02 ‚Äì Degradaci√≥n acumulada fuerte\n",
    "        # -------------------------------\n",
    "        base_R02 = 0.35 + 0.5 * t  # crece fuertemente hacia el final\n",
    "        ruido_R02 = np.random.normal(0, 0.03)\n",
    "        criticidad_R02 = np.clip(base_R02 + ruido_R02, 0.0, 1.0)\n",
    "\n",
    "        # -------------------------------\n",
    "        # R01 ‚Äì Controlado pero con se√±ales d√©biles\n",
    "        # -------------------------------\n",
    "        base_R01 = 0.25 + 0.25 * t  # leve pendiente\n",
    "        ruido_R01 = np.random.normal(0, 0.03)\n",
    "        criticidad_R01 = np.clip(base_R01 + ruido_R01, 0.0, 1.0)\n",
    "\n",
    "        # -------------------------------\n",
    "        # R03 ‚Äì Estable con variaciones leves\n",
    "        # -------------------------------\n",
    "        base_R03 = 0.18  # valor central estable\n",
    "        ruido_R03 = np.random.uniform(-0.03, 0.03)\n",
    "        pico_R03 = 0.02 if random.random() < 0.05 else 0.0\n",
    "        criticidad_R03 = np.clip(base_R03 + ruido_R03 + pico_R03, 0.0, 1.0)\n",
    "\n",
    "\n",
    "        registros.append(\n",
    "            {\n",
    "                \"id_dia\": id_dia,\n",
    "                \"fecha\": fecha,\n",
    "                \"semana\": semana,\n",
    "                \"criticidad_R01\": criticidad_R01,\n",
    "                \"criticidad_R02\": criticidad_R02,\n",
    "                \"criticidad_R03\": criticidad_R03,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df_tray = pd.DataFrame(registros)\n",
    "    return df_tray\n",
    "\n",
    "df_trayectorias = generar_trayectorias_riesgo(calendario)\n",
    "print(\"Trayectorias generadas:\", df_trayectorias.shape)\n",
    "df_trayectorias.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trayectorias.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7187d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2.2 ‚Äì Trayectoria ponderada global por d√≠a y agregados por semana\n",
    "\n",
    "PESOS_RIESGO_GLOBAL = {\n",
    "    \"R01\": 0.25,\n",
    "    \"R02\": 0.5,\n",
    "    \"R03\": 0.25,\n",
    "}\n",
    "\n",
    "def agregar_trayectoria_global(df_tray):\n",
    "    df = df_tray.copy()\n",
    "\n",
    "    df[\"criticidad_global\"] = (\n",
    "        df[\"criticidad_R01\"] * PESOS_RIESGO_GLOBAL[\"R01\"]\n",
    "        + df[\"criticidad_R02\"] * PESOS_RIESGO_GLOBAL[\"R02\"]\n",
    "        + df[\"criticidad_R03\"] * PESOS_RIESGO_GLOBAL[\"R03\"]\n",
    "    )\n",
    "\n",
    "    # Agregados semanales para facilitar gr√°ficos en la demo (medias por semana)\n",
    "    df_semana = (\n",
    "        df.groupby(\"semana\", as_index=False)[\n",
    "            [\n",
    "                \"criticidad_R01\",\n",
    "                \"criticidad_R02\",\n",
    "                \"criticidad_R03\",\n",
    "                \"criticidad_global\",\n",
    "            ]\n",
    "        ]\n",
    "        .mean()\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"criticidad_R01\": \"criticidad_R01_media\",\n",
    "                \"criticidad_R02\": \"criticidad_R02_media\",\n",
    "                \"criticidad_R03\": \"criticidad_R03_media\",\n",
    "                \"criticidad_global\": \"criticidad_global_media\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df, df_semana\n",
    "\n",
    "df_trayectorias, df_trayectorias_semana = agregar_trayectoria_global(df_trayectorias)\n",
    "\n",
    "print(\"df_trayectorias:\", df_trayectorias.shape)\n",
    "print(\"df_trayectorias_semana:\", df_trayectorias_semana.shape)\n",
    "df_trayectorias_semana.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 3.1a ‚Äî Funciones base de probabilidad (PD, NMS, IMEN)\n",
    "# Versi√≥n FINAL calibrada (mining-realistic) para STDE v3\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def base_PD(criticidad, fdo_row):\n",
    "    \"\"\"\n",
    "    HAZARD (Peligro Detectado)\n",
    "    Debe ser el evento m√°s frecuente en miner√≠a (~70‚Äì80% del total).\n",
    "    \"\"\"\n",
    "    p = (\n",
    "        0.18                       # antes 0.10\n",
    "        + 0.12 * criticidad        # antes 0.05\n",
    "    )\n",
    "\n",
    "    p *= (1 + 0.20 * fdo_row[\"fdo_congestion\"])\n",
    "\n",
    "    return min(p, 0.40)            # antes 0.25\n",
    "\n",
    "\n",
    "\n",
    "def base_NM(criticidad, fdo_row):\n",
    "    \"\"\"\n",
    "    NMS (Near Miss)\n",
    "    Frecuencia intermedia (ideal 15‚Äì25%), solo sube con criticidad alta.\n",
    "    \"\"\"\n",
    "    p = (\n",
    "        0.04                      # base antes 0.02 ‚Üí duplicamos\n",
    "        + 0.06 * criticidad       # antes 0.04 ‚Üí m√°s sensibilidad\n",
    "    )\n",
    "\n",
    "    # fdo_clima sube efecto realista\n",
    "    p *= (1 + 0.10 * fdo_row[\"fdo_clima\"])\n",
    "\n",
    "    return min(p, 0.12)           # antes 0.07 ‚Üí l√≠mite mayor\n",
    "          # hard cap 7%\n",
    "\n",
    "\n",
    "def base_IM(criticidad, fdo_row):\n",
    "    \"\"\"\n",
    "    IMEN (Incidente Menor)\n",
    "    RARO: 0.3‚Äì1.5% normalmente.\n",
    "    \"\"\"\n",
    "    p = (\n",
    "        0.003                      # base 0.3%\n",
    "        + 0.01 * criticidad        # criticidad aporta hasta 1%\n",
    "    )\n",
    "\n",
    "    p *= (1 + 0.05 * fdo_row[\"fdo_fatiga\"])\n",
    "\n",
    "    return min(p, 0.02)            # l√≠mite duro 2%\n",
    "\n",
    "\n",
    "print(\"Funciones PD / NMS / IM recalibradas (versi√≥n final).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb82c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3.1b ‚Äì Versi√≥n corregida de modular_por_fdo (redefine solo esta funci√≥n)\n",
    "\n",
    "def modular_por_fdo(prob, fdo_row):\n",
    "    \"\"\"\n",
    "    Ajusta la probabilidad con los FDO diarios.\n",
    "    Reglas STDE v3:\n",
    "      - producci√≥n, congesti√≥n y fatiga aumentan prob. de eventos\n",
    "      - dotaci√≥n baja ‚Üí aumenta riesgo\n",
    "      - clima extremo ‚Üí altera probabilidad\n",
    "    \"\"\"\n",
    "    factor = (\n",
    "        1.0\n",
    "        + 0.30 * fdo_row[\"fdo_produccion\"]\n",
    "        + 0.20 * fdo_row[\"fdo_congestion\"]\n",
    "        + 0.20 * fdo_row[\"fdo_fatiga\"]\n",
    "        + 0.10 * (1.0 - fdo_row[\"fdo_dotacion\"])   # menos dotaci√≥n ‚Üí m√°s riesgo\n",
    "        + 0.10 * abs(fdo_row[\"fdo_clima\"] - 0.5)   # clima muy bueno o muy malo altera el riesgo\n",
    "    )\n",
    "\n",
    "    prob_mod = np.clip(prob * factor, 0.0, 0.99)\n",
    "    return prob_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# 3.2a Preprocesar roles y tareas agrupados por √°rea (usando 'area_operacional')\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Validar columnas reales\n",
    "assert \"area_operacional\" in df_roles.columns, \"El cat√°logo de roles no contiene 'area_operacional'\"\n",
    "assert \"area_operacional\" in df_tareas.columns, \"El cat√°logo de tareas no contiene 'area_operacional'\"\n",
    "\n",
    "# Crear diccionarios √°rea ‚Üí lista de roles / tareas\n",
    "roles_por_area = (\n",
    "    df_roles\n",
    "    .groupby(\"area_operacional\")[\"id\"]\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "tareas_por_area = (\n",
    "    df_tareas\n",
    "    .groupby(\"area_operacional\")[\"id\"]\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "print(\"Roles por √°rea:\", {k: len(v) for k,v in roles_por_area.items()})\n",
    "print(\"Tareas por √°rea:\", {k: len(v) for k,v in tareas_por_area.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb46ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 3.2 ‚Äî Generar eventos diarios (HAZARD / NMS / IMEN)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def generar_eventos_v3(\n",
    "    calendario, df_trayectorias, df_fdo, oms,\n",
    "    roles_por_area, tareas_por_area\n",
    "):\n",
    "    eventos = []\n",
    "\n",
    "    # Extraer mapeo riesgo_por_area desde OMS v3\n",
    "    riesgo_por_area = oms.get(\"mapeos_operacionales\", {}).get(\"riesgo_por_area\", {})\n",
    "\n",
    "    for _, row in calendario.iterrows():\n",
    "        fecha = row[\"fecha\"]\n",
    "        semana = row[\"semana\"]\n",
    "        id_dia = row[\"id_dia\"]\n",
    "\n",
    "        # FDO y trayectoria para ese d√≠a\n",
    "        fdo_row = df_fdo[df_fdo[\"id_dia\"] == id_dia].iloc[0]\n",
    "        tra_row = df_trayectorias[df_trayectorias[\"id_dia\"] == id_dia].iloc[0]\n",
    "\n",
    "        # Recorrer cada √°rea definida en la OMS\n",
    "        for area_id, riesgos_area in riesgo_por_area.items():\n",
    "\n",
    "            # 1) Elegir riesgo dominante del √°rea seg√∫n pesos\n",
    "            riesgos = [x[\"riesgo_id\"] for x in riesgos_area]\n",
    "            pesos = [x[\"peso_relativo\"] for x in riesgos_area]\n",
    "            riesgo_elegido = random.choices(riesgos, weights=pesos, k=1)[0]\n",
    "\n",
    "            # 2) Obtener criticidad del riesgo elegido\n",
    "            criticidad = float(tra_row[f\"criticidad_{riesgo_elegido}\"])\n",
    "\n",
    "            # 3) Calcular probabilidad de evento\n",
    "            p_pd = base_PD(criticidad, fdo_row)\n",
    "            p_nm = base_NM(criticidad, fdo_row)\n",
    "            p_im = base_IM(criticidad, fdo_row)\n",
    "\n",
    "            # 4) Selecci√≥n del tipo narrativo\n",
    "            evento_tipo = None\n",
    "            r = random.random()\n",
    "\n",
    "            # Orden l√≥gico PD ‚Üí NMS ‚Üí IMEN\n",
    "            # Probabilidad total\n",
    "            p_total = p_pd + p_nm + p_im\n",
    "            r = random.random()\n",
    "\n",
    "            evento_tipo = None\n",
    "            if r < p_pd:\n",
    "                evento_tipo = \"HAZARD\"\n",
    "            elif r < p_pd + p_nm:\n",
    "                evento_tipo = \"NMS\"\n",
    "            elif r < p_pd + p_nm + p_im:\n",
    "                evento_tipo = \"IMEN\"\n",
    "\n",
    "\n",
    "            # 5) Si no ocurri√≥ evento, pasar al siguiente √°rea\n",
    "            if not evento_tipo:\n",
    "                continue\n",
    "\n",
    "            # 6) Seleccionar rol/tarea v√°lidos del √°rea\n",
    "            roles_area = roles_por_area.get(area_id, [])\n",
    "            tareas_area = tareas_por_area.get(area_id, [])\n",
    "\n",
    "            if not roles_area or not tareas_area:\n",
    "                continue  # Seguridad\n",
    "\n",
    "            rol_id = random.choice(roles_area)\n",
    "            tarea_id = random.choice(tareas_area)\n",
    "\n",
    "            # 7) Registrar evento\n",
    "            eventos.append({\n",
    "                \"id_dia\": id_dia,\n",
    "                \"fecha\": fecha,\n",
    "                \"semana\": semana,\n",
    "                \"id_area\": area_id,\n",
    "                \"riesgo_id\": riesgo_elegido,\n",
    "                \"tipo_evento\": evento_tipo,\n",
    "                \"criticidad\": criticidad,\n",
    "                \"rol_id\": rol_id,\n",
    "                \"tarea_id\": tarea_id,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(eventos)\n",
    "\n",
    "\n",
    "# Ejecutar\n",
    "df_eventos = generar_eventos_v3(\n",
    "    calendario, df_trayectorias, df_fdo, oms,\n",
    "    roles_por_area, tareas_por_area\n",
    ")\n",
    "\n",
    "print(\"Eventos generados:\", df_eventos.shape)\n",
    "df_eventos.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3da8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eventos[\"tipo_evento\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eventos[\"riesgo_id\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c71fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eventos.groupby(\"semana\")[\"tipo_evento\"].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c9be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 3.3 ‚Äî Inyecci√≥n del lunes cr√≠tico (versi√≥n C.3 ‚Äî √°rea fija MRA)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def inyectar_lunes_critico(df_eventos, df_trayectorias, oms,\n",
    "                           roles_por_area, tareas_por_area):\n",
    "    \"\"\"\n",
    "    Inyecta el lunes cr√≠tico como un evento compuesto:\n",
    "      - LC_EVT_00 (evento maestro)\n",
    "      - LC_EVT_01 (NMS R01)\n",
    "      - LC_EVT_02 (NMS R02)\n",
    "\n",
    "    NOTA:\n",
    "    Para mantener la coherencia narrativa, el lunes cr√≠tico\n",
    "    siempre ocurre en el √°rea MRA, independientemente del\n",
    "    mapeo operacional general.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fecha del LC definida en OMS v3\n",
    "    fecha_lc = pd.to_datetime(\n",
    "        oms[\"escenario_operacion\"][\"lunes_critico\"][\"fecha\"]\n",
    "    ).date()\n",
    "\n",
    "    semana_lc = 13\n",
    "    id_dia_lc = -1\n",
    "\n",
    "    # Criticidad real (√∫ltimo d√≠a semana 12)\n",
    "    def criticidad_real(riesgo_id):\n",
    "        try:\n",
    "            fila = df_trayectorias[df_trayectorias[\"semana\"] == 12].iloc[-1]\n",
    "            return float(fila[f\"criticidad_{riesgo_id}\"])\n",
    "        except:\n",
    "            return 0.8\n",
    "\n",
    "    # Forzar √°rea = MRA\n",
    "    area_lc = \"MRA\"\n",
    "\n",
    "    # Selecci√≥n de rol/tarea solo para MRA\n",
    "    def elegir_rol_tarea_MRA():\n",
    "        roles = roles_por_area.get(area_lc, [])\n",
    "        tareas = tareas_por_area.get(area_lc, [])\n",
    "        if not roles or not tareas:\n",
    "            return None, None\n",
    "        return random.choice(roles), random.choice(tareas)\n",
    "\n",
    "    rol_R01, tarea_R01 = elegir_rol_tarea_MRA()\n",
    "    rol_R02, tarea_R02 = elegir_rol_tarea_MRA()\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Evento Maestro (compuesto)\n",
    "    # ------------------------------------------------------------\n",
    "    registros.append({\n",
    "        \"id_evento\": \"LC_EVT_00\",\n",
    "        \"id_evento_compuesto\": None,\n",
    "        \"id_dia\": id_dia_lc,\n",
    "        \"fecha\": fecha_lc,\n",
    "        \"semana\": semana_lc,\n",
    "\n",
    "        \"id_area\": area_lc,\n",
    "        \"rol_id\": None,\n",
    "        \"tarea_id\": None,\n",
    "\n",
    "        \"riesgo_id\": None,\n",
    "        \"tipo_evento\": \"NMS_COMPUESTO\",\n",
    "        \"criticidad\": max(criticidad_real(\"R01\"), criticidad_real(\"R02\")),\n",
    "        \"es_lunes_critico\": True,\n",
    "\n",
    "        \"descripcion_evento\": (\n",
    "            \"Durante una inspecci√≥n rutinaria en un andamio m√≥vil, un trabajador perdi√≥ \"\n",
    "            \"el equilibrio y simult√°neamente se le cay√≥ una llave desde altura. \"\n",
    "            \"El arn√©s detuvo la ca√≠da y la herramienta no impact√≥ a nadie.\"\n",
    "        ),\n",
    "        \"evento_principal_ocurrido\": (\n",
    "            \"P√©rdida de equilibrio en andamio que activa ca√≠da detenida (R01) \"\n",
    "            \"y ca√≠da de objeto (R02).\"\n",
    "        )\n",
    "    })\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Sub-evento R01 (Ca√≠da detenida)\n",
    "    # ------------------------------------------------------------\n",
    "    registros.append({\n",
    "        \"id_evento\": \"LC_EVT_01\",\n",
    "        \"id_evento_compuesto\": \"LC_EVT_00\",\n",
    "        \"id_dia\": id_dia_lc,\n",
    "        \"fecha\": fecha_lc,\n",
    "        \"semana\": semana_lc,\n",
    "\n",
    "        \"id_area\": area_lc,\n",
    "        \"rol_id\": rol_R01,\n",
    "        \"tarea_id\": tarea_R01,\n",
    "\n",
    "        \"riesgo_id\": \"R01\",\n",
    "        \"tipo_evento\": \"NMS\",\n",
    "        \"criticidad\": criticidad_real(\"R01\"),\n",
    "        \"es_lunes_critico\": True,\n",
    "\n",
    "        \"descripcion_evento\": (\n",
    "            \"Ca√≠da detenida por arn√©s al perder equilibrio en el andamio.\"\n",
    "        ),\n",
    "        \"evento_principal_ocurrido\": \"Ca√≠da detenida.\"\n",
    "    })\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Sub-evento R02 (Ca√≠da de herramienta)\n",
    "    # ------------------------------------------------------------\n",
    "    registros.append({\n",
    "        \"id_evento\": \"LC_EVT_02\",\n",
    "        \"id_evento_compuesto\": \"LC_EVT_00\",\n",
    "        \"id_dia\": id_dia_lc,\n",
    "        \"fecha\": fecha_lc,\n",
    "        \"semana\": semana_lc,\n",
    "\n",
    "        \"id_area\": area_lc,\n",
    "        \"rol_id\": rol_R02,\n",
    "        \"tarea_id\": tarea_R02,\n",
    "\n",
    "        \"riesgo_id\": \"R02\",\n",
    "        \"tipo_evento\": \"NMS\",\n",
    "        \"criticidad\": criticidad_real(\"R02\"),\n",
    "        \"es_lunes_critico\": True,\n",
    "\n",
    "        \"descripcion_evento\": (\n",
    "            \"Ca√≠da de herramienta desde el andamio sin impacto en personas.\"\n",
    "        ),\n",
    "        \"evento_principal_ocurrido\": \"Ca√≠da de objeto.\"\n",
    "    })\n",
    "\n",
    "    df_lc = pd.DataFrame(registros)\n",
    "\n",
    "    df_final = (\n",
    "        pd.concat([df_eventos, df_lc], ignore_index=True)\n",
    "        .sort_values([\"fecha\", \"id_area\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"‚Üí Lunes cr√≠tico inyectado correctamente (√°rea=MRA).\")\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# Reinyectar LC\n",
    "df_eventos = inyectar_lunes_critico(\n",
    "    df_eventos, df_trayectorias, oms,\n",
    "    roles_por_area, tareas_por_area\n",
    ")\n",
    "\n",
    "df_eventos[df_eventos[\"es_lunes_critico\"] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3868532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 4.1 ‚Äî Observaciones OPG¬± (ruido operacional por √°rea)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def generar_observaciones_opg(calendario, df_fdo, roles_por_area, tareas_por_area):\n",
    "    registros = []\n",
    "\n",
    "    # Reglas de carga por √°rea\n",
    "    OPG_AREA = {\n",
    "        \"MRA\": (2, 4),   # Rango por d√≠a\n",
    "        \"CHP\": (1, 3),\n",
    "        \"PLC\": (1, 3),\n",
    "        \"STM\": (1, 3),\n",
    "        \"TME\": (1, 3),\n",
    "    }\n",
    "\n",
    "    for _, row in calendario.iterrows():\n",
    "        fecha = row[\"fecha\"]\n",
    "        semana = row[\"semana\"]\n",
    "        id_dia = row[\"id_dia\"]\n",
    "\n",
    "        # FDO del d√≠a\n",
    "        fdo_row = df_fdo[df_fdo[\"id_dia\"] == id_dia].iloc[0]\n",
    "        fatiga = fdo_row[\"fdo_fatiga\"]\n",
    "        congestion = fdo_row[\"fdo_congestion\"]\n",
    "\n",
    "        for area_id, (lo, hi) in OPG_AREA.items():\n",
    "\n",
    "            # Cantidad de observaciones del d√≠a en esa √°rea\n",
    "            n_opg = random.randint(lo, hi)\n",
    "\n",
    "            for _ in range(n_opg):\n",
    "\n",
    "                # Selecci√≥n de roles/tareas v√°lidos\n",
    "                roles_area = roles_por_area.get(area_id, [])\n",
    "                tareas_area = tareas_por_area.get(area_id, [])\n",
    "\n",
    "                if not roles_area or not tareas_area:\n",
    "                    continue\n",
    "\n",
    "                rol_id = random.choice(roles_area)\n",
    "                tarea_id = random.choice(tareas_area)\n",
    "\n",
    "                # Estado OPG+ / OPG‚àí\n",
    "                # Congesti√≥n y fatiga aumentan probabilidad de OPG‚àí\n",
    "                p_neg = 0.03 + 0.10 * congestion + 0.07 * fatiga\n",
    "                p_neg = min(p_neg, 0.20)  # l√≠mite duro: 20%\n",
    "\n",
    "                estado = \"OPG-\" if random.random() < p_neg else \"OPG+\"\n",
    "\n",
    "                registros.append({\n",
    "                    \"id_observacion\": None,  # se completa luego en consolidaci√≥n\n",
    "                    \"fecha\": fecha,\n",
    "                    \"semana\": semana,\n",
    "                    \"id_area\": area_id,\n",
    "                    \"rol_observador_id\": rol_id,\n",
    "                    \"rol_observado_id\": rol_id,  # simplificaci√≥n STDE v3\n",
    "                    \"tarea_id\": tarea_id,\n",
    "                    \"tipo_observacion\": \"OPG\",\n",
    "                    \"estado\": estado,\n",
    "                    \"riesgo_id\": None,\n",
    "                    \"is_control_critico\": False,\n",
    "                    \"control_critico_id\": None,\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(registros)\n",
    "\n",
    "\n",
    "# Ejecutar OPG¬±\n",
    "df_opg = generar_observaciones_opg(\n",
    "    calendario, df_fdo, roles_por_area, tareas_por_area\n",
    ")\n",
    "\n",
    "print(\"OPG generadas:\", df_opg.shape)\n",
    "df_opg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ecd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 4.2 ‚Äì OCC¬± planificadas/espont√°neas seg√∫n ranking proactivo\n",
    "#   - Total objetivo ‚âà 200 OCC en 12 semanas (~16/semana)\n",
    "#   - Solo riesgos R01‚ÄìR03\n",
    "#   - Distribuci√≥n semanal:\n",
    "#       50% riesgo top entre R01‚ÄìR03\n",
    "#       30% segundo\n",
    "#       20% tercero\n",
    "#   - NO dependen de eventos, solo de:\n",
    "#       - ranking semanal (modelo proactivo)\n",
    "#       - mapeos_operacionales.riesgo_por_area (OMS v3)\n",
    "#       - cat√°logos de roles/tareas/controles\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def generar_occ_planificadas(\n",
    "    calendario,\n",
    "    oms,\n",
    "    roles_por_area,\n",
    "    tareas_por_area,\n",
    "    df_controles,\n",
    "    path_proactivo=PATH_PROACTIVO,\n",
    "    occ_totales_por_semana=16,\n",
    "):\n",
    "    \"\"\"\n",
    "    Genera OCC¬± para 12 semanas, usando el ranking proactivo v4.4:\n",
    "    - Se lee el CSV del modelo proactivo (stde_proactivo_semanal_v4_4.csv)\n",
    "    - Para cada semana se determina el orden relativo de R01, R02, R03.\n",
    "    - Se asignan ~16 OCC semanales distribuidas 50/30/20 seg√∫n ese orden.\n",
    "    - Las OCC se distribuyen en d√≠as y √°reas usando mapeos_operacionales.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------\n",
    "    # 1) Cargar ranking proactivo\n",
    "    # ------------------------------\n",
    "    df_pro = pd.read_csv(path_proactivo)\n",
    "\n",
    "    # Normalizar nombres de columnas si fuese necesario\n",
    "    # Se espera: \"semana_id\", \"riesgo_id\", \"score_proactivo\", \"rank_proactivo\"\n",
    "    cols_lower = {c.lower(): c for c in df_pro.columns}\n",
    "    if \"semana_id\" not in df_pro.columns and \"semana_id\" in cols_lower:\n",
    "        df_pro.rename(columns={cols_lower[\"semana_id\"]: \"semana_id\"}, inplace=True)\n",
    "    if \"riesgo_id\" not in df_pro.columns and \"riesgo_id\" in cols_lower:\n",
    "        df_pro.rename(columns={cols_lower[\"riesgo_id\"]: \"riesgo_id\"}, inplace=True)\n",
    "    if \"rank_proactivo\" not in df_pro.columns and \"rank_proactivo\" in cols_lower:\n",
    "        df_pro.rename(columns={cols_lower[\"rank_proactivo\"]: \"rank_proactivo\"}, inplace=True)\n",
    "\n",
    "    # Nos quedamos solo con R01‚ÄìR03\n",
    "    df_pro_3 = df_pro[df_pro[\"riesgo_id\"].isin([\"R01\", \"R02\", \"R03\"])].copy()\n",
    "\n",
    "    # ------------------------------\n",
    "    # 2) Mapeos de √°reas por riesgo (OMS v3)\n",
    "    # ------------------------------\n",
    "    riesgo_por_area = oms.get(\"mapeos_operacionales\", {}).get(\"riesgo_por_area\", {})\n",
    "\n",
    "    def elegir_area_para_riesgo(riesgo_id):\n",
    "        \"\"\"Elige un √°rea para el riesgo dado, usando los pesos de mapeos_operacionales.\"\"\"\n",
    "        areas = []\n",
    "        pesos = []\n",
    "\n",
    "        for area_id, lista_riesgos in riesgo_por_area.items():\n",
    "            for item in lista_riesgos:\n",
    "                if item[\"riesgo_id\"] == riesgo_id:\n",
    "                    areas.append(area_id)\n",
    "                    pesos.append(item[\"peso_relativo\"])\n",
    "        if not areas:\n",
    "            return None\n",
    "        return random.choices(areas, weights=pesos, k=1)[0]\n",
    "\n",
    "    # ------------------------------\n",
    "    # 3) Controles cr√≠ticos por riesgo\n",
    "    # ------------------------------\n",
    "    # El cat√°logo de controles tiene \"riesgo_asociado\" y \"id\"\n",
    "    controles_por_riesgo = (\n",
    "        df_controles.groupby(\"riesgo_asociado\")[\"id\"]\n",
    "        .apply(list).to_dict()\n",
    "    )\n",
    "\n",
    "    def elegir_control_critico(riesgo_id):\n",
    "        ids = controles_por_riesgo.get(riesgo_id, [])\n",
    "        if not ids:\n",
    "            return None\n",
    "        return random.choice(ids)\n",
    "\n",
    "    # ------------------------------\n",
    "    # 4) Bucle por semana (1‚Äì12)\n",
    "    # ------------------------------\n",
    "    registros = []\n",
    "\n",
    "    semanas_unicas = sorted(calendario[\"semana\"].unique())\n",
    "    # asumimos 12 semanas numeradas 1..12\n",
    "    for semana in semanas_unicas:\n",
    "        # Ranking para esa semana (solo R01‚ÄìR03)\n",
    "        df_sem = df_pro_3[df_pro_3[\"semana_id\"] == semana]\n",
    "\n",
    "        if df_sem.empty:\n",
    "            continue\n",
    "\n",
    "        # Ordenar por rank_proactivo (1 = m√°s cr√≠tico)\n",
    "        df_sem_ordenado = df_sem.sort_values(\"rank_proactivo\")\n",
    "        riesgos_ordenados = df_sem_ordenado[\"riesgo_id\"].tolist()\n",
    "\n",
    "        # Si faltan riesgos, rellenar orden con los que falten\n",
    "        for r in [\"R01\", \"R02\", \"R03\"]:\n",
    "            if r not in riesgos_ordenados:\n",
    "                riesgos_ordenados.append(r)\n",
    "\n",
    "        # Tomar solo los 3 en orden\n",
    "        r_top, r_mid, r_low = riesgos_ordenados[:3]\n",
    "\n",
    "        # Cantidades por riesgo (50% / 30% / 20%)\n",
    "        n_total = occ_totales_por_semana\n",
    "        n_top = int(round(n_total * 0.50))\n",
    "        n_mid = int(round(n_total * 0.30))\n",
    "        n_low = n_total - n_top - n_mid  # lo que falta\n",
    "\n",
    "        plan_semana = [\n",
    "            (r_top, n_top),\n",
    "            (r_mid, n_mid),\n",
    "            (r_low, n_low),\n",
    "        ]\n",
    "\n",
    "        # D√≠as de esta semana en el calendario\n",
    "        dias_sem = calendario[calendario[\"semana\"] == semana][\"fecha\"].tolist()\n",
    "        if not dias_sem:\n",
    "            continue\n",
    "\n",
    "        # ------------------------------\n",
    "        # 5) Generar OCC para esta semana\n",
    "        # ------------------------------\n",
    "        for riesgo_id, n_occ in plan_semana:\n",
    "\n",
    "            for _ in range(n_occ):\n",
    "                # Elegir d√≠a\n",
    "                fecha = random.choice(dias_sem)\n",
    "\n",
    "                # Elegir √°rea seg√∫n mapeo OMS\n",
    "                area_id = elegir_area_para_riesgo(riesgo_id)\n",
    "                if area_id is None:\n",
    "                    continue\n",
    "\n",
    "                # Roles / tareas del √°rea\n",
    "                roles_area = roles_por_area.get(area_id, [])\n",
    "                tareas_area = tareas_por_area.get(area_id, [])\n",
    "\n",
    "                if not roles_area or not tareas_area:\n",
    "                    continue\n",
    "\n",
    "                # OCC+ / OCC‚àí (por defecto 70% positivas, 30% negativas)\n",
    "                estado = \"OCC+\" if random.random() < 0.7 else \"OCC-\"\n",
    "\n",
    "                # Control cr√≠tico (si existe)\n",
    "                control_id = elegir_control_critico(riesgo_id)\n",
    "                is_cc = control_id is not None\n",
    "\n",
    "                # Buscar semana/id_dia consistentes con calendario\n",
    "                row_dia = calendario[calendario[\"fecha\"] == fecha]\n",
    "                if row_dia.empty:\n",
    "                    continue\n",
    "\n",
    "                semana_real = int(row_dia[\"semana\"].iloc[0])\n",
    "\n",
    "                registros.append({\n",
    "                    \"id_observacion\": None,\n",
    "                    \"fecha\": fecha,\n",
    "                    \"semana\": semana_real,\n",
    "                    \"id_area\": area_id,\n",
    "                    \"rol_observador_id\": random.choice(roles_area),\n",
    "                    \"rol_observado_id\": random.choice(roles_area),\n",
    "                    \"tarea_id\": random.choice(tareas_area),\n",
    "\n",
    "                    \"tipo_observacion\": \"OCC\",\n",
    "                    \"estado\": estado,\n",
    "\n",
    "                    \"riesgo_id\": riesgo_id,\n",
    "                    \"is_control_critico\": is_cc,\n",
    "                    \"control_critico_id\": control_id,\n",
    "\n",
    "                    # OCC no vienen de eventos ‚Üí sin v√≠nculo a df_eventos\n",
    "                    \"id_evento_origen\": None,\n",
    "                    \"tipo_evento_origen\": None,\n",
    "                })\n",
    "\n",
    "    df_occ = pd.DataFrame(registros)\n",
    "    return df_occ\n",
    "\n",
    "\n",
    "# Ejecutar generaci√≥n OCC planificadas\n",
    "df_occ = generar_occ_planificadas(\n",
    "    calendario,\n",
    "    oms,\n",
    "    roles_por_area,\n",
    "    tareas_por_area,\n",
    "    df_controles,\n",
    "    path_proactivo=PATH_PROACTIVO,\n",
    "    occ_totales_por_semana=16,   # 16 x 12 semanas ‚âà 192 OCC (rango cercano a 200)\n",
    ")\n",
    "\n",
    "print(\"OCC generadas:\", df_occ.shape)\n",
    "print(df_occ[\"riesgo_id\"].value_counts(dropna=False))\n",
    "print(df_occ[\"estado\"].value_counts(dropna=False))\n",
    "df_occ.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ac999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 4.3 ‚Äî Consolidar OPG y OCC en un solo dataframe final\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def consolidar_observaciones(df_opg, df_occ):\n",
    "    \"\"\"\n",
    "    Une OPG y OCC en un √∫nico DF y asigna IDs √∫nicos.\n",
    "    Se mantiene completamente alineado al STDE_SCHEMA v3.\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1) Unir dataframes (si OCC est√° vac√≠o no rompe nada)\n",
    "    # --------------------------------------------------------\n",
    "    df_obs = pd.concat([df_opg, df_occ], ignore_index=True)\n",
    "\n",
    "    if df_obs.empty:\n",
    "        print(\"‚ö† No se generaron observaciones.\")\n",
    "        return df_obs\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 2) Generar ID √∫nico para cada observaci√≥n\n",
    "    # Formato: OBS_000001\n",
    "    # --------------------------------------------------------\n",
    "    df_obs[\"id_observacion\"] = [\n",
    "        f\"OBS_{i:06d}\" for i in range(1, len(df_obs) + 1)\n",
    "    ]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3) Asegurar tipos finales para consistencia\n",
    "    # --------------------------------------------------------\n",
    "    df_obs[\"is_control_critico\"] = df_obs[\"is_control_critico\"].astype(bool)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 4) Ordenar columnas seg√∫n STDE_SCHEMA\n",
    "    # --------------------------------------------------------\n",
    "    columnas_finales = [\n",
    "        \"id_observacion\",\n",
    "        \"fecha\",\n",
    "        \"semana\",\n",
    "        \"id_area\",\n",
    "        \"rol_observador_id\",\n",
    "        \"rol_observado_id\",\n",
    "        \"tarea_id\",\n",
    "        \"tipo_observacion\",     # OPG / OCC\n",
    "        \"estado\",               # OPG+, OPG‚àí, OCC+, OCC‚àí\n",
    "        \"riesgo_id\",\n",
    "        \"is_control_critico\",\n",
    "        \"control_critico_id\",\n",
    "    ]\n",
    "\n",
    "    # Algunas columnas pueden faltar (ej: OCC vac√≠o)\n",
    "    columnas_presentes = [c for c in columnas_finales if c in df_obs.columns]\n",
    "\n",
    "    df_obs = df_obs[columnas_presentes]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 5) Ordenar por fecha y √°rea (m√°s ordenado para an√°lisis)\n",
    "    # --------------------------------------------------------\n",
    "    df_obs = df_obs.sort_values(by=[\"fecha\", \"id_area\"]).reset_index(drop=True)\n",
    "\n",
    "    return df_obs\n",
    "\n",
    "\n",
    "# Ejecutar consolidaci√≥n\n",
    "df_observaciones = consolidar_observaciones(df_opg, df_occ)\n",
    "\n",
    "print(\"Observaciones totales:\", df_observaciones.shape)\n",
    "df_observaciones.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 5.1 ‚Äî Auditor√≠as AUF reactivas (solo NMS e IMEN)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def generar_auditorias_reactivas(df_eventos, roles_por_area):\n",
    "    \"\"\"\n",
    "    Genera auditor√≠as reactivas cuando existen:\n",
    "      - Near Miss (NMS)\n",
    "      - Incidente Menor (IMEN)\n",
    "\n",
    "    Regla STDE v3:\n",
    "      ‚Üí auditor√≠a en ‚â§48 horas\n",
    "      ‚Üí √°rea del evento\n",
    "      ‚Üí riesgo focal del evento\n",
    "    \"\"\"\n",
    "\n",
    "    registros = []\n",
    "    id_counter = 1\n",
    "\n",
    "    eventos_reactivos = df_eventos[\n",
    "        df_eventos[\"tipo_evento\"].isin([\"NMS\", \"IMEN\"])\n",
    "    ]\n",
    "\n",
    "    for _, ev in eventos_reactivos.iterrows():\n",
    "\n",
    "        # Fecha AUDIT entre el mismo d√≠a y 2 d√≠as despu√©s\n",
    "        fecha_ev = ev[\"fecha\"]\n",
    "        delta = random.choice([0, 1, 2])\n",
    "        fecha_aud = fecha_ev + timedelta(days=delta)\n",
    "\n",
    "        # Rol auditor aleatorio del √°rea\n",
    "        area = ev[\"id_area\"]\n",
    "        posibles_roles = roles_por_area.get(area, [])\n",
    "        rol_auditor = random.choice(posibles_roles) if posibles_roles else None\n",
    "\n",
    "        registros.append({\n",
    "            \"id_auditoria\": f\"AUF_R_{id_counter:05d}\",\n",
    "            \"fecha\": fecha_aud,\n",
    "            \"semana\": ev[\"semana\"],\n",
    "            \"id_area\": ev[\"id_area\"],\n",
    "            \"riesgo_focal\": ev[\"riesgo_id\"],\n",
    "            \"tipo_auditoria\": \"AUF\",        # √∫nica categor√≠a en STDE v3\n",
    "            \"origen\": \"reactiva\",\n",
    "            \"rol_auditor_id\": rol_auditor,\n",
    "            \"id_evento_asociado\": ev.get(\"id_evento\", None),\n",
    "        })\n",
    "\n",
    "        id_counter += 1\n",
    "\n",
    "    return pd.DataFrame(registros)\n",
    "\n",
    "\n",
    "# Ejecutar AUF REACTIVAS\n",
    "df_auf_reactivas = generar_auditorias_reactivas(df_eventos, roles_por_area)\n",
    "\n",
    "print(\"AUF reactivas generadas:\", df_auf_reactivas.shape)\n",
    "df_auf_reactivas.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb23169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 5.2 ‚Äî Auditor√≠as AUF planificadas (corregida)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def generar_auditorias_planificadas(calendario, roles_por_area, riesgos=[\"R01\",\"R02\",\"R03\"]):\n",
    "    \"\"\"\n",
    "    Genera ~5 auditor√≠as por riesgo por mes (~15 por mes total),\n",
    "    distribuidas aleatoriamente dentro de cada mes.\n",
    "    \"\"\"\n",
    "\n",
    "    registros = []\n",
    "    id_counter = 1\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # üî• FIX: asegurar que 'fecha' sea datetime\n",
    "    # ---------------------------------------------------------\n",
    "    calendario[\"fecha\"] = pd.to_datetime(calendario[\"fecha\"])\n",
    "\n",
    "    # Determinar meses presentes en el calendario\n",
    "    calendario[\"mes\"] = calendario[\"fecha\"].dt.to_period(\"M\")\n",
    "    meses = calendario[\"mes\"].unique()\n",
    "\n",
    "    for mes in meses:\n",
    "        df_mes = calendario[calendario[\"mes\"] == mes]\n",
    "\n",
    "        for riesgo in riesgos:\n",
    "            # generar 5 auditor√≠as planificadas para este riesgo\n",
    "            for _ in range(5):\n",
    "\n",
    "                row = df_mes.sample(1).iloc[0]\n",
    "                fecha = row[\"fecha\"]\n",
    "                semana = row[\"semana\"]\n",
    "\n",
    "                # seleccionar √°rea y rol auditor\n",
    "                area = random.choice(list(roles_por_area.keys()))\n",
    "                rol = random.choice(roles_por_area[area])\n",
    "\n",
    "                registros.append({\n",
    "                    \"id_auditoria\": f\"AUF_P_{id_counter:05d}\",\n",
    "                    \"fecha\": fecha,\n",
    "                    \"semana\": semana,\n",
    "                    \"id_area\": area,\n",
    "                    \"riesgo_focal\": riesgo,\n",
    "                    \"tipo_auditoria\": \"AUF\",\n",
    "                    \"origen\": \"planificada\",\n",
    "                    \"rol_auditor_id\": rol,\n",
    "                })\n",
    "\n",
    "                id_counter += 1\n",
    "\n",
    "    return pd.DataFrame(registros)\n",
    "\n",
    "\n",
    "# Ejecutar AUF PLANIFICADAS\n",
    "df_auf_planificadas = generar_auditorias_planificadas(calendario, roles_por_area)\n",
    "\n",
    "print(\"AUF planificadas:\", df_auf_planificadas.shape)\n",
    "df_auf_planificadas.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca99209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 5.3 ‚Äî Consolidar Auditor√≠as AUF (reactivas + planificadas)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def consolidar_auditorias(df_auf_reactivas, df_auf_planificadas):\n",
    "    \"\"\"\n",
    "    Une AUF reactivas y planificadas en un √∫nico dataframe,\n",
    "    asigna IDs √∫nicos finales y ordena columnas seg√∫n STDE_SCHEMA v3.\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1) Unir ambos dataframes\n",
    "    # --------------------------------------------------------\n",
    "    df_aud = pd.concat(\n",
    "        [df_auf_reactivas, df_auf_planificadas],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    if df_aud.empty:\n",
    "        print(\"‚ö† No se generaron auditor√≠as.\")\n",
    "        return df_aud\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 2) Asegurar fecha como datetime (FIX del error)\n",
    "    # --------------------------------------------------------\n",
    "    df_aud[\"fecha\"] = pd.to_datetime(df_aud[\"fecha\"])\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3) Asignaci√≥n de ID final √∫nico\n",
    "    #    Formato: AUF_000001\n",
    "    # --------------------------------------------------------\n",
    "    df_aud[\"id_auditoria_final\"] = [\n",
    "        f\"AUF_{i:06d}\" for i in range(1, len(df_aud) + 1)\n",
    "    ]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 4) Reordenar columnas seg√∫n STDE_SCHEMA v3\n",
    "    # --------------------------------------------------------\n",
    "    columnas_finales = [\n",
    "        \"id_auditoria_final\",\n",
    "        \"fecha\",\n",
    "        \"semana\",\n",
    "        \"id_area\",\n",
    "        \"riesgo_focal\",\n",
    "        \"tipo_auditoria\",\n",
    "        \"origen\",\n",
    "        \"rol_auditor_id\",\n",
    "        \"id_evento_asociado\",\n",
    "    ]\n",
    "\n",
    "    columnas_presentes = [c for c in columnas_finales if c in df_aud.columns]\n",
    "    df_aud = df_aud[columnas_presentes]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 5) Ordenar (ya no fallar√°)\n",
    "    # --------------------------------------------------------\n",
    "    df_aud = df_aud.sort_values(by=[\"fecha\", \"id_area\"]).reset_index(drop=True)\n",
    "\n",
    "    return df_aud\n",
    "\n",
    "\n",
    "# Ejecutar consolidaci√≥n final\n",
    "df_auditorias = consolidar_auditorias(df_auf_reactivas, df_auf_planificadas)\n",
    "\n",
    "print(\"AUDITOR√çAS TOTALES:\", df_auditorias.shape)\n",
    "df_auditorias.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.1 ‚Äì Cargar ranking proactivo v4.4 (archivo final)\n",
    "\n",
    "df_proactivo = pd.read_csv(PATH_PROACTIVO)\n",
    "\n",
    "# Validaciones base\n",
    "print(\"Proactivo v4.4 cargado correctamente:\", df_proactivo.shape)\n",
    "print(\"Columnas:\", list(df_proactivo.columns))\n",
    "\n",
    "# Vista r√°pida\n",
    "df_proactivo.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b85d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.2 ‚Äì Calcular thresholds por semana y riesgo\n",
    "\n",
    "def calcular_thresholds(df_proactivo):\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    for semana in sorted(df_proactivo[\"semana_id\"].unique()):\n",
    "        df_sem = df_proactivo[df_proactivo[\"semana_id\"] == semana]\n",
    "\n",
    "        scores = df_sem[\"score_proactivo\"].values\n",
    "\n",
    "        # Thresholds basados en percentiles (modelo real)\n",
    "        thr_alerta  = np.round(np.percentile(scores, 60), 2)\n",
    "        thr_critico = np.round(np.percentile(scores, 80), 2)\n",
    "\n",
    "        for _, row in df_sem.iterrows():\n",
    "            registros.append({\n",
    "                \"semana_id\": semana,\n",
    "                \"riesgo_id\": row[\"riesgo_id\"],\n",
    "                \"score_proactivo\": row[\"score_proactivo\"],\n",
    "                \"rank_proactivo\": row[\"rank_proactivo\"],\n",
    "                \"threshold_alerta\": thr_alerta,\n",
    "                \"threshold_critico\": thr_critico\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(registros)\n",
    "\n",
    "\n",
    "df_proactivo_thresholds = calcular_thresholds(df_proactivo)\n",
    "print(\"Thresholds generados:\", df_proactivo_thresholds.shape)\n",
    "df_proactivo_thresholds.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59140f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.1 ‚Äî Cargar ranking semanal del modelo proactivo (CSV)\n",
    "\n",
    "PATH_PROACTIVO = os.path.join(BASE_PATH, \"stde_proactivo_semanal_v4_4.csv\")\n",
    "\n",
    "df_proactivo = pd.read_csv(PATH_PROACTIVO)\n",
    "\n",
    "print(\"Ranking proactivo cargado:\", df_proactivo.shape)\n",
    "df_proactivo.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.2 ‚Äî Quedarnos solo con los riesgos modelados (R01‚ÄìR03)\n",
    "\n",
    "def filtrar_top3_proactivo(df):\n",
    "    \"\"\"\n",
    "    Mantiene solo los riesgos R01‚ÄìR03 del ranking semanal.\n",
    "    Cada fila representa semana + riesgo + ranking_pos.\n",
    "    \"\"\"\n",
    "    df2 = df[df[\"riesgo_id\"].isin([\"R01\", \"R02\", \"R03\"])].copy()\n",
    "    return df2\n",
    "\n",
    "df_proactivo_top3 = filtrar_top3_proactivo(df_proactivo)\n",
    "\n",
    "print(\"Ranking filtrado a R01‚ÄìR03:\", df_proactivo_top3.shape)\n",
    "df_proactivo_top3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.3 ‚Äî Integrar trayectorias reales vs ranking semanal\n",
    "\n",
    "# Trayectorias promedio por semana (ya las ten√≠as en df_trayectorias_semana)\n",
    "df_tray_sem.rename(columns={\"semana\": \"semana_id\"}, inplace=True)\n",
    "\n",
    "df_compare = df_proactivo_top3.merge(\n",
    "    df_tray_sem,\n",
    "    left_on=\"semana\",\n",
    "    right_on=\"semana_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"Comparaci√≥n ranking + trayectoria:\", df_compare.shape)\n",
    "df_compare.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e39ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.4 ‚Äî Clasificaci√≥n K9 basada en criticidad y tendencia\n",
    "\n",
    "def clasificacion_k9(criticidad_actual, criticidad_prev):\n",
    "    \"\"\"\n",
    "    Solo 2 colores:\n",
    "    - ROJO     = alta criticidad + tendencia fuerte\n",
    "    - AMARILLO = moderado + tendencia leve\n",
    "    \"\"\"\n",
    "    tendencia = criticidad_actual - criticidad_prev if criticidad_prev is not None else 0.0\n",
    "\n",
    "    if criticidad_actual > 0.70 and tendencia > 0.05:\n",
    "        return \"ROJO\"\n",
    "\n",
    "    if criticidad_actual > 0.50 or tendencia > 0.02:\n",
    "        return \"AMARILLO\"\n",
    "\n",
    "    return \"AMARILLO\"  # Por dise√±o K9 (no usamos VERDE)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Aplicar clasificaci√≥n por riesgo / semana\n",
    "# ---------------------------------------------------\n",
    "clasificaciones = []\n",
    "\n",
    "for _, row in df_compare.iterrows():\n",
    "    riesgo = row[\"riesgo_id\"]\n",
    "    semana = row[\"semana\"]\n",
    "\n",
    "    crit_col = f\"criticidad_{riesgo}_media\"\n",
    "\n",
    "    criticidad_actual = row.get(crit_col, None)\n",
    "\n",
    "    # Criticidad semana anterior\n",
    "    if semana > 1:\n",
    "        prev = df_compare[\n",
    "            (df_compare[\"riesgo_id\"] == riesgo) &\n",
    "            (df_compare[\"semana\"] == semana - 1)\n",
    "        ]\n",
    "        criticidad_prev = float(prev[crit_col]) if len(prev) > 0 else None\n",
    "    else:\n",
    "        criticidad_prev = None\n",
    "\n",
    "    color = clasificacion_k9(criticidad_actual, criticidad_prev)\n",
    "\n",
    "    clasificaciones.append(color)\n",
    "\n",
    "df_compare[\"k9_color\"] = clasificaciones\n",
    "\n",
    "print(\"Clasificaci√≥n aplicada.\")\n",
    "df_compare.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c3c917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.5 ‚Äî Output final del bloque 6.x\n",
    "\n",
    "df_resultado_6x = df_compare[[\n",
    "    \"semana\",\n",
    "    \"riesgo_id\",\n",
    "    \"ranking_pos\",\n",
    "    \"criticidad_R01_media\",\n",
    "    \"criticidad_R02_media\",\n",
    "    \"criticidad_R03_media\",\n",
    "    \"criticidad_global_media\",\n",
    "    \"k9_color\"\n",
    "]].sort_values([\"semana\", \"ranking_pos\"])\n",
    "\n",
    "print(\"Resultado final 6.x:\", df_resultado_6x.shape)\n",
    "df_resultado_6x.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fdefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.6 ‚Äî Se√±ales individuales por riesgo\n",
    "\n",
    "def calcular_senales_individuales(df_compare):\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    for semana in sorted(df_compare[\"semana\"].unique()):\n",
    "        df_sem = df_compare[df_compare[\"semana\"] == semana]\n",
    "\n",
    "        # Ordenar riesgos por ranking_pos\n",
    "        df_sem_sorted = df_sem.sort_values(\"ranking_pos\")\n",
    "\n",
    "        # Obtener criticidad del top1 para la se√±al ‚Äúdistancia‚Äù\n",
    "        riesgo_top1 = df_sem_sorted.iloc[0][\"riesgo_id\"]\n",
    "        crit_top1 = df_sem_sorted.iloc[0][f\"criticidad_{riesgo_top1}_media\"]\n",
    "\n",
    "        for _, row in df_sem_sorted.iterrows():\n",
    "            riesgo = row[\"riesgo_id\"]\n",
    "\n",
    "            crit_actual = row[f\"criticidad_{riesgo}_media\"]\n",
    "\n",
    "            # Criticidad previa\n",
    "            if semana > 1:\n",
    "                df_prev = df_compare[\n",
    "                    (df_compare[\"riesgo_id\"] == riesgo) &\n",
    "                    (df_compare[\"semana\"] == semana - 1)\n",
    "                ]\n",
    "                crit_prev = float(df_prev[f\"criticidad_{riesgo}_media\"]) if len(df_prev) > 0 else None\n",
    "            else:\n",
    "                crit_prev = None\n",
    "\n",
    "            tendencia = (crit_actual - crit_prev) if crit_prev is not None else 0.0\n",
    "\n",
    "            # Severidad interna K9 (SEV1/2/3)\n",
    "            if row[\"k9_color\"] == \"ROJO\":\n",
    "                sev = \"SEV3\"\n",
    "            else:\n",
    "                sev = \"SEV2\" if tendencia > 0.03 else \"SEV1\"\n",
    "\n",
    "            # Distancia al top 1\n",
    "            dist_top1 = crit_actual - crit_top1\n",
    "\n",
    "            # Shock del lunes cr√≠tico (solo aparece en semana 13 en el CSV final)\n",
    "            lc_shock = 1 if semana == 13 and riesgo in [\"R01\", \"R02\"] else 0\n",
    "            lc_delta = tendencia if lc_shock == 1 else 0.0\n",
    "\n",
    "            registros.append({\n",
    "                \"semana\": semana,\n",
    "                \"riesgo_id\": riesgo,\n",
    "                \"ranking_pos\": row[\"ranking_pos\"],\n",
    "\n",
    "                # Se√±ales STDE\n",
    "                \"criticidad\": crit_actual,\n",
    "                \"tendencia\": tendencia,\n",
    "                \"dist_top1\": dist_top1,\n",
    "\n",
    "                # Se√±al interna K9\n",
    "                \"sev_k9\": sev,\n",
    "\n",
    "                # Se√±ales lunes cr√≠tico\n",
    "                \"lc_shock\": lc_shock,\n",
    "                \"lc_delta\": lc_delta,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(registros)\n",
    "\n",
    "\n",
    "df_senales = calcular_senales_individuales(df_compare)\n",
    "\n",
    "print(\"Se√±ales individuales generadas:\", df_senales.shape)\n",
    "df_senales.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda7a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 7.1 ‚Äì Extraer se√±ales del lunes cr√≠tico para recalibraci√≥n\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def extraer_senales_lunes_critico(df_eventos, df_tray_sem):\n",
    "    \"\"\"\n",
    "    Extrae el impacto del lunes cr√≠tico para R01 y R02:\n",
    "    - criticidad previa (semana 12)\n",
    "    - shock (criticidad del LC_evento)\n",
    "    - delta (shock - criticidad_previa)\n",
    "    Retorna un diccionario estructurado.\n",
    "    \"\"\"\n",
    "\n",
    "    # Eventos R01 / R02 del LC\n",
    "    df_lc = df_eventos[df_eventos[\"es_lunes_critico\"] == True].copy()\n",
    "\n",
    "    senales = {}\n",
    "\n",
    "    for riesgo in [\"R01\", \"R02\"]:\n",
    "        df_r = df_lc[df_lc[\"riesgo_id\"] == riesgo]\n",
    "        if df_r.empty:\n",
    "            continue\n",
    "\n",
    "        criticidad_lc = float(df_r[\"criticidad\"].iloc[0])\n",
    "\n",
    "        # criticidad promedio semana 12\n",
    "        crit_prev = float(\n",
    "            df_tray_sem[df_tray_sem[\"semana\"] == 12][f\"criticidad_{riesgo}_media\"]\n",
    "        )\n",
    "\n",
    "        senales[riesgo] = {\n",
    "            \"criticidad_previa\": round(crit_prev, 4),\n",
    "            \"criticidad_lc\": round(criticidad_lc, 4),\n",
    "            \"delta\": round(criticidad_lc - crit_prev, 4)\n",
    "        }\n",
    "\n",
    "    return senales\n",
    "\n",
    "\n",
    "senales_lc = extraer_senales_lunes_critico(df_eventos, df_tray_semana)\n",
    "\n",
    "print(\"Se√±ales del lunes cr√≠tico extra√≠das:\")\n",
    "senales_lc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 7.2 ‚Äì Funci√≥n conceptual de recalibraci√≥n del modelo proactivo\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def recalibrar_proactivo(df_proactivo, senales_lc):\n",
    "    \"\"\"\n",
    "    K9 recalibra su interpretaci√≥n del modelo proactivo posterior al LC.\n",
    "\n",
    "    No cambia los scores del modelo proactivo.\n",
    "    Genera 'pesos cognitivos' para ajustar qu√© tan relevante\n",
    "    se vuelve un riesgo despu√©s del shock del lunes cr√≠tico.\n",
    "\n",
    "    F√≥rmula:\n",
    "        peso_k9 = 1 + (delta * 1.5)         si delta > 0\n",
    "        peso_k9 = 1                         en otros casos\n",
    "\n",
    "    Retorna DataFrame con columna nueva 'peso_k9'.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df_proactivo.copy()\n",
    "    df[\"peso_k9\"] = 1.0\n",
    "\n",
    "    for riesgo, datos in senales_lc.items():\n",
    "        delta = datos[\"delta\"]\n",
    "        if delta > 0:\n",
    "            incremento = 1 + (1.5 * delta)\n",
    "            df.loc[df[\"riesgo_id\"] == riesgo, \"peso_k9\"] = incremento\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_proactivo_recal = recalibrar_proactivo(df_proactivo_thresholds, senales_lc)\n",
    "\n",
    "print(\"Recalibraci√≥n conceptual aplicada (peso_k9):\")\n",
    "df_proactivo_recal.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e97fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 7.3 ‚Äì Se√±ales recalibradas finales para AnalystNode K9\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def generar_senales_k9(df_tray_sem, df_proactivo_recal):\n",
    "    \"\"\"\n",
    "    Genera para cada semana y riesgo (R01-R03):\n",
    "\n",
    "    - ranking_pos\n",
    "    - score_proactivo\n",
    "    - threshold_norm\n",
    "    - peso_k9\n",
    "    - criticidad_media\n",
    "    - tendencia\n",
    "    - dist_top1\n",
    "    - sev_k9 (SEV1‚ÄìSEV3)\n",
    "    \"\"\"\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    semanas = sorted(df_tray_sem[\"semana\"].unique())\n",
    "\n",
    "    for semana in semanas:\n",
    "        for riesgo in [\"R01\", \"R02\", \"R03\"]:\n",
    "\n",
    "            # criticidad media\n",
    "            crit = float(\n",
    "                df_tray_sem[df_tray_sem[\"semana\"] == semana][f\"criticidad_{riesgo}_media\"]\n",
    "            )\n",
    "\n",
    "            # tendencia semana a semana\n",
    "            if semana == 1:\n",
    "                tendencia = 0.0\n",
    "            else:\n",
    "                crit_prev = float(\n",
    "                    df_tray_sem[df_tray_sem[\"semana\"] == semana - 1][f\"criticidad_{riesgo}_media\"]\n",
    "                )\n",
    "                tendencia = crit - crit_prev\n",
    "\n",
    "            # ranking del proactivo\n",
    "            df_rk = df_proactivo_recal[\n",
    "                (df_proactivo_recal[\"semana_id\"] == semana) &\n",
    "                (df_proactivo_recal[\"riesgo_id\"] == riesgo)\n",
    "            ]\n",
    "\n",
    "            if df_rk.empty:\n",
    "                continue\n",
    "\n",
    "            rank_pos = int(df_rk[\"rank_proactivo\"].iloc[0])\n",
    "            score = float(df_rk[\"threshold_norm\"].iloc[0])\n",
    "            peso_k9 = float(df_rk[\"peso_k9\"].iloc[0])\n",
    "\n",
    "            # distancia al top1 de esa semana\n",
    "            score_top1 = float(\n",
    "                df_proactivo_recal[df_proactivo_recal[\"semana_id\"] == semana]\n",
    "                .sort_values(\"rank_proactivo\")\n",
    "                .iloc[0][\"threshold_norm\"]\n",
    "            )\n",
    "            dist_top1 = score - score_top1\n",
    "\n",
    "            # severidad K9\n",
    "            if score >= 0.8:\n",
    "                sev = \"SEV3\"\n",
    "            elif score >= 0.5:\n",
    "                sev = \"SEV2\"\n",
    "            else:\n",
    "                sev = \"SEV1\"\n",
    "\n",
    "            registros.append({\n",
    "                \"semana\": semana,\n",
    "                \"riesgo_id\": riesgo,\n",
    "                \"criticidad_media\": round(crit, 4),\n",
    "                \"tendencia\": round(tendencia, 4),\n",
    "                \"rank_pos\": rank_pos,\n",
    "                \"score\": round(score, 4),\n",
    "                \"dist_top1\": round(dist_top1, 4),\n",
    "                \"sev_k9\": sev,\n",
    "                \"peso_k9\": round(peso_k9, 4),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(registros)\n",
    "\n",
    "\n",
    "df_senales_k9 = generar_senales_k9(df_tray_semana, df_proactivo_recal)\n",
    "\n",
    "print(\"Se√±ales K9 generadas:\", df_senales_k9.shape)\n",
    "df_senales_k9.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd5d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 8.1 ‚Äì Exportaci√≥n de datasets STDE v3 a CSV\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "\n",
    "# Usamos la ruta que definiste al inicio\n",
    "OUTPUT_DIR = \"../data/synthetic/\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "files_to_export = {\n",
    "    \"stde_trayectorias_diarias.csv\": df_trayectorias,\n",
    "    \"stde_trayectorias_semanales.csv\": df_tray_semana,\n",
    "    \"stde_eventos.csv\": df_eventos,\n",
    "    \"stde_observaciones.csv\": df_observaciones,\n",
    "    \"stde_auditorias.csv\": df_auditorias,\n",
    "    \"stde_fdo_diario.csv\": df_fdo_diario,\n",
    "    \"stde_proactivo_semanal_v4_4_thresholds.csv\": df_proactivo_thresholds,\n",
    "    \"stde_senales_k9.csv\": df_senales_k9,\n",
    "}\n",
    "\n",
    "for filename, df in files_to_export.items():\n",
    "    path = os.path.join(OUTPUT_DIR, filename)\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"‚úì Exportado: {filename} ‚Üí {path}\")\n",
    "\n",
    "print(\"\\nExportaci√≥n STDE v3 completada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 8.2 ‚Äì Checks de consistencia STDE v3\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"CHECKS DE CONSISTENCIA ‚Äì STDE v3\")\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "errores = []\n",
    "\n",
    "# 1) Validar que todos los riesgos usados existan en la ontolog√≠a\n",
    "riesgos_validos = set(df_riesgos[\"id_riesgo\"].unique())\n",
    "\n",
    "riesgos_eventos = set(df_eventos[\"riesgo_id\"].dropna().unique())\n",
    "riesgos_observ = set(df_observaciones[\"riesgo_id\"].dropna().unique())\n",
    "\n",
    "if not riesgos_eventos.issubset(riesgos_validos):\n",
    "    errores.append(\"‚ùå Riesgos desconocidos en eventos.\")\n",
    "else:\n",
    "    print(\"‚úì Riesgos v√°lidos en eventos.\")\n",
    "\n",
    "if not riesgos_observ.issubset(riesgos_validos):\n",
    "    errores.append(\"‚ùå Riesgos desconocidos en observaciones.\")\n",
    "else:\n",
    "    print(\"‚úì Riesgos v√°lidos en observaciones.\")\n",
    "\n",
    "\n",
    "# 2) Validar √°reas\n",
    "areas_validas = set(df_areas[\"id_area\"].unique())\n",
    "\n",
    "areas_eventos = set(df_eventos[\"id_area\"].unique())\n",
    "areas_observ = set(df_observaciones[\"id_area\"].unique())\n",
    "\n",
    "if not areas_eventos.issubset(areas_validas):\n",
    "    errores.append(\"‚ùå √Åreas desconocidas en eventos.\")\n",
    "else:\n",
    "    print(\"‚úì √Åreas v√°lidas en eventos.\")\n",
    "\n",
    "if not areas_observ.issubset(areas_validas):\n",
    "    errores.append(\"‚ùå √Åreas desconocidas en observaciones.\")\n",
    "else:\n",
    "    print(\"‚úì √Åreas v√°lidas en observaciones.\")\n",
    "\n",
    "\n",
    "# 3) Validar roles y tareas\n",
    "roles_validos = set(df_roles[\"id_rol\"].unique())\n",
    "tareas_validas = set(df_tareas[\"id_tarea\"].unique())\n",
    "\n",
    "roles_eventos = set(df_eventos[\"rol_id\"].dropna().unique())\n",
    "tareas_eventos = set(df_eventos[\"tarea_id\"].dropna().unique())\n",
    "\n",
    "if not roles_eventos.issubset(roles_validos):\n",
    "    errores.append(\"‚ùå Roles desconocidos en eventos.\")\n",
    "else:\n",
    "    print(\"‚úì Roles v√°lidos en eventos.\")\n",
    "\n",
    "if not tareas_eventos.issubset(tareas_validas):\n",
    "    errores.append(\"‚ùå Tareas desconocidas en eventos.\")\n",
    "else:\n",
    "    print(\"‚úì Tareas v√°lidas en eventos.\")\n",
    "\n",
    "\n",
    "# 4) Validar que exista lunes cr√≠tico y con EXACTAMENTE 3 registros (compuesto + 2 NMS)\n",
    "df_lc = df_eventos[df_eventos[\"es_lunes_critico\"] == True]\n",
    "\n",
    "if df_lc.shape[0] != 3:\n",
    "    errores.append(f\"‚ùå Lunes cr√≠tico incorrecto: {df_lc.shape[0]} registros.\")\n",
    "else:\n",
    "    print(\"‚úì Lunes cr√≠tico correcto (3 registros).\")\n",
    "\n",
    "\n",
    "# 5) Validar proporciones de OPG ¬± y OCC ¬±\n",
    "if \"estado\" in df_observaciones.columns:\n",
    "    pct_opg = (df_observaciones[\"tipo_observacion\"] == \"OPG\").mean()\n",
    "    pct_occ = (df_observaciones[\"tipo_observacion\"] == \"OCC\").mean()\n",
    "\n",
    "    print(f\"Proporci√≥n OPG: {pct_opg:.2f} | OCC: {pct_occ:.2f}\")\n",
    "\n",
    "    if pct_occ > 0.40:\n",
    "        errores.append(\"‚ùå OCC demasiado altas (deben ser ~10‚Äì25%).\")\n",
    "else:\n",
    "    print(\"‚ö† df_observaciones no tiene columna 'estado'.\")\n",
    "\n",
    "\n",
    "# 6) Validar n√∫mero de AUF respecto a NMS/IMEN\n",
    "n_nms = (df_eventos[\"tipo_evento\"] == \"NMS\").sum()\n",
    "n_imen = (df_eventos[\"tipo_evento\"] == \"IMEN\").sum()\n",
    "n_auf = df_auditorias.shape[0]\n",
    "\n",
    "if n_auf < n_nms:\n",
    "    errores.append(\"‚ùå AUF insuficientes frente a NMS.\")\n",
    "else:\n",
    "    print(\"‚úì AUF coherentes con eventos reales.\")\n",
    "\n",
    "\n",
    "# 7) Resultado final\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "if errores:\n",
    "    print(\"‚ùå Se detectaron problemas:\")\n",
    "    for e in errores:\n",
    "        print(\"   -\", e)\n",
    "else:\n",
    "    print(\"‚úì Todos los checks STDE v3 se cumplen correctamente.\")\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e60b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 8.3 ‚Äî DataFrame semanal unificado: k9_weekly_signals.parquet\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Partir del df_senales_k9 ya generado (secci√≥n 6.x)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "df_weekly = df_senales_k9.copy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Agregar columnas indicadoras √∫tiles para el AnalystNode\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "df_weekly[\"is_top3\"] = df_weekly[\"rank_proactivo\"].apply(lambda r: r <= 3)\n",
    "df_weekly[\"riesgo_dominante\"] = df_weekly.groupby(\"semana\")[\"criticidad\"].transform(\n",
    "    lambda x: x == x.max()\n",
    ")\n",
    "\n",
    "# Marcamos semana del lunes cr√≠tico\n",
    "semana_lc = int(df_eventos[df_eventos[\"es_lunes_critico\"] == True][\"semana\"].iloc[0])\n",
    "df_weekly[\"es_semana_lunes_critico\"] = df_weekly[\"semana\"] == semana_lc\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Guardar en parquet\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "path_parquet = os.path.join(OUTPUT_DIR, \"k9_weekly_signals.parquet\")\n",
    "\n",
    "table = pa.Table.from_pandas(df_weekly)\n",
    "pq.write_table(table, path_parquet)\n",
    "\n",
    "print(f\"‚úì Archivo semanal unificado exportado: {path_parquet}\")\n",
    "df_weekly.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 8.4 ‚Äî Generar payload JSON para AnalystNode (por semana y global)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import json\n",
    "\n",
    "def build_week_payload(semana, df_weekly, df_eventos, df_observaciones, df_auditorias):\n",
    "    df_w = df_weekly[df_weekly[\"semana\"] == semana]\n",
    "\n",
    "    # Eventos de esa semana\n",
    "    eventos_w = df_eventos[df_eventos[\"semana\"] == semana]\n",
    "    observ_w = df_observaciones[df_observaciones[\"semana\"] == semana]\n",
    "    auf_w = df_auditorias[df_auditorias[\"semana\"] == semana]\n",
    "\n",
    "    payload = {\n",
    "        \"semana\": int(semana),\n",
    "        \"riesgos\": [],\n",
    "        \"eventos\": eventos_w.to_dict(orient=\"records\"),\n",
    "        \"observaciones\": observ_w.to_dict(orient=\"records\"),\n",
    "        \"auditorias\": auf_w.to_dict(orient=\"records\"),\n",
    "        \"es_semana_lunes_critico\": bool((df_w[\"es_semana_lunes_critico\"]).any())\n",
    "    }\n",
    "\n",
    "    for _, row in df_w.iterrows():\n",
    "        payload[\"riesgos\"].append({\n",
    "            \"riesgo_id\": row[\"riesgo_id\"],\n",
    "            \"criticidad_media\": float(row[\"criticidad\"]),\n",
    "            \"criticidad_ponderada\": float(row[\"criticidad_ponderada\"]),\n",
    "            \"zona_alerta\": row[\"zona_alerta\"],         # None / \"amarilla\" / \"roja\"\n",
    "            \"tendencia\": row[\"tendencia\"],            # \"estable\" / \"leve_subida\" / \"acelerada\"\n",
    "            \"rank_proactivo\": int(row[\"rank_proactivo\"]),\n",
    "            \"is_top3\": bool(row[\"is_top3\"]),\n",
    "            \"riesgo_dominante\": bool(row[\"riesgo_dominante\"]),\n",
    "        })\n",
    "\n",
    "    return payload\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Generar payloads por semana\n",
    "# ------------------------------------------------------------\n",
    "payloads_semanales = {}\n",
    "for semana in df_weekly[\"semana\"].unique():\n",
    "    payloads_semanales[f\"semana_{int(semana)}\"] = build_week_payload(\n",
    "        semana,\n",
    "        df_weekly,\n",
    "        df_eventos,\n",
    "        df_observaciones,\n",
    "        df_auditorias\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Payload global (para precontexto del AnalystNode)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "payload_global = {\n",
    "    \"descripcion\": \"STDE v3 ‚Äì Se√±ales cruzadas completas para el AnalystNode\",\n",
    "    \"periodo\": f\"{calendario['fecha'].iloc[0]} ‚Üí {calendario['fecha'].iloc[-1]}\",\n",
    "    \"k9_signals_parquet\": \"k9_weekly_signals.parquet\",\n",
    "    \"semanas\": payloads_semanales\n",
    "}\n",
    "\n",
    "# Guardar JSON\n",
    "json_path = os.path.join(OUTPUT_DIR, \"k9_weekly_payloads.json\")\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(payload_global, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úì Payload JSON exportado: {json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Celda 8.7 ‚Äî Payloads JSON para AnalystNode y PredictorNode\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import json\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Payload PredictorNode ‚Äî formato pensado para K9 v3.1\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "predictor_payload = {\n",
    "    \"descripcion\": \"STDE v3 ‚Äì Se√±ales completas para PredictorNode\",\n",
    "    \"periodo\": {\n",
    "        \"inicio\": str(calendario[\"fecha\"].iloc[0]),\n",
    "        \"fin\": str(calendario[\"fecha\"].iloc[-1]),\n",
    "        \"semanas\": int(calendario[\"semana\"].max())\n",
    "    },\n",
    "\n",
    "    \"riesgos_modelados\": [\"R01\", \"R02\", \"R03\"],\n",
    "\n",
    "    \"trayectorias\": df_trayectorias_semana.to_dict(orient=\"records\"),\n",
    "\n",
    "    \"eventos\": {\n",
    "        \"totales\": int(df_eventos.shape[0]),\n",
    "        \"por_semana\": df_eventos.groupby(\"semana\").size().to_dict(),\n",
    "        \"por_riesgo\": df_eventos[\"riesgo_id\"].value_counts().to_dict(),\n",
    "        \"near_miss\": int((df_eventos[\"tipo_evento\"] == \"NMS\").sum()),\n",
    "        \"incident_menor\": int((df_eventos[\"tipo_evento\"] == \"IMEN\").sum()),\n",
    "        \"lunes_critico\": df_eventos[df_eventos[\"es_lunes_critico\"] == True].to_dict(orient=\"records\")\n",
    "    },\n",
    "\n",
    "    \"observaciones\": {\n",
    "        \"totales\": int(df_observaciones.shape[0]),\n",
    "        \"opg\": int((df_observaciones[\"tipo_observacion\"] == \"OPG\").sum()),\n",
    "        \"occ\": int((df_observaciones[\"tipo_observacion\"] == \"OCC\").sum()),\n",
    "        \"occ_negativas\": int((df_observaciones[\"estado\"] == \"OCC-\").sum())\n",
    "    },\n",
    "\n",
    "    \"auditorias\": {\n",
    "        \"totales\": int(df_auditorias.shape[0]),\n",
    "        \"por_semana\": df_auditorias.groupby(\"semana\").size().to_dict(),\n",
    "        \"reactivas\": int((df_auditorias[\"tipo\"] == \"AUF\").sum()),\n",
    "        \"planificadas\": int((df_auditorias[\"tipo\"] == \"PLANIFICADA\").sum()\n",
    "                            if \"PLANIFICADA\" in df_auditorias[\"tipo\"].unique()\n",
    "                            else 0)\n",
    "    },\n",
    "\n",
    "    \"modelo_proactivo\": {\n",
    "        \"archivo_fuente\": \"stde_proactivo_semanal_v4_4.csv\",\n",
    "        \"ranking\": df_proactivo_thresholds.to_dict(orient=\"records\"),\n",
    "    },\n",
    "\n",
    "    \"k9_signals\": {\n",
    "        \"por_semana\": df_senales_k9.to_dict(orient=\"records\"),\n",
    "        \"ruta_parquet\": \"k9_weekly_signals.parquet\"\n",
    "    },\n",
    "\n",
    "    \"fdo\": df_fdo_diario.to_dict(orient=\"records\")\n",
    "}\n",
    "\n",
    "# Guardar JSON PredictorNode\n",
    "predictor_json_path = os.path.join(OUTPUT_DIR, \"k9_predictor_payload.json\")\n",
    "with open(predictor_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(predictor_payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úì Payload PredictorNode exportado: {predictor_json_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k9_mining_safety",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
