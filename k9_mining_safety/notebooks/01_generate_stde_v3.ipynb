{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ef0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 0.1 – Imports y configuración de paths correctos\n",
    "\n",
    "import os\n",
    "import random\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Rutas REALES según tu proyecto:\n",
    "# notebooks/\n",
    "#   └── 01_generate_stde_v3.ipynb\n",
    "# data/\n",
    "#     ├── oms/\n",
    "#     ├── ontology/\n",
    "#     └── synthetic/\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "RUTA_OMS = \"../data/oms/99_oms_stde_v3.yaml\"\n",
    "\n",
    "# Catálogos en ontology/\n",
    "PATH_ROLES     = \"../data/ontology/10_catalogo_roles_v3.yaml\"\n",
    "PATH_TAREAS    = \"../data/ontology/12_catalogo_tareas_v1.yaml\"\n",
    "PATH_AREAS     = \"../data/ontology/13_catalogo_areas_operacionales_v1.yaml\"\n",
    "PATH_RIESGOS   = \"../data/ontology/01_catalogo_riesgos_v8.yaml\"\n",
    "PATH_CONTROLES = \"../data/ontology/02_catalogo_controles_v6.yaml\"\n",
    "\n",
    "# Modelo proactivo en oms/\n",
    "PATH_PROACTIVO = \"../data/oms/stde_proactivo_semanal_v4_4.csv\"\n",
    "\n",
    "# Directorio de salida (synthetic/)\n",
    "OUTPUT_DIR = \"../data/synthetic/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Configuración de aleatoriedad\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 0.2 – Cargar OMS v3\n",
    "\n",
    "def cargar_yaml(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "oms = cargar_yaml(PATH_OMS)\n",
    "\n",
    "# Accesos rápidos a secciones relevantes de la OMS v3\n",
    "meta = oms.get(\"meta\", {})\n",
    "stde_cfg = oms.get(\"stde\", {})\n",
    "fdo_cfg = oms.get(\"fdo\", {})\n",
    "escenario_cfg = oms.get(\"escenario_operacion\", {})\n",
    "mapeos_operacionales = oms.get(\"mapeos_operacionales\", {})\n",
    "proactivo_cfg = oms.get(\"proactivo\", {})\n",
    "\n",
    "lunes_critico_cfg = escenario_cfg.get(\"lunes_critico\", {})\n",
    "eventos_lunes_critico = lunes_critico_cfg.get(\"eventos_sinteticos\", [])\n",
    "\n",
    "print(\"Versión OMS:\", meta.get(\"version\"))\n",
    "print(\"Fecha inicio escenario:\", escenario_cfg.get(\"fecha_inicio\"))\n",
    "print(\"Número de semanas:\", escenario_cfg.get(\"numero_semanas\"))\n",
    "print(\"Eventos del lunes crítico:\", len(eventos_lunes_critico))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 0.3 – Cargar catálogos de ontología (roles, tareas, áreas, riesgos, controles)\n",
    "\n",
    "def cargar_catalogo_roles(path):\n",
    "    data = cargar_yaml(path)\n",
    "    # Asumimos que el YAML tiene una lista principal \"roles\"\n",
    "    roles = data.get(\"roles\", data)  # fallback por si la raíz ya es lista\n",
    "    return pd.DataFrame(roles)\n",
    "\n",
    "def cargar_catalogo_tareas(path):\n",
    "    data = cargar_yaml(path)\n",
    "    tareas = data.get(\"tareas\", data)\n",
    "    return pd.DataFrame(tareas)\n",
    "\n",
    "def cargar_catalogo_areas(path):\n",
    "    data = cargar_yaml(path)\n",
    "    areas = data.get(\"areas_operacionales\", data.get(\"areas\", data))\n",
    "    return pd.DataFrame(areas)\n",
    "\n",
    "def cargar_catalogo_riesgos(path):\n",
    "    data = cargar_yaml(path)\n",
    "    riesgos = data.get(\"riesgos\", data)\n",
    "    return pd.DataFrame(riesgos)\n",
    "\n",
    "def cargar_catalogo_controles(path):\n",
    "    data = cargar_yaml(path)\n",
    "    controles = data.get(\"controles\", data)\n",
    "    return pd.DataFrame(controles)\n",
    "\n",
    "df_roles = cargar_catalogo_roles(PATH_ROLES)\n",
    "df_tareas = cargar_catalogo_tareas(PATH_TAREAS)\n",
    "df_areas = cargar_catalogo_areas(PATH_AREAS)\n",
    "df_riesgos = cargar_catalogo_riesgos(PATH_RIESGOS)\n",
    "df_controles = cargar_catalogo_controles(PATH_CONTROLES)\n",
    "\n",
    "print(\"Roles:\", df_roles.shape, \"Tareas:\", df_tareas.shape, \"Áreas:\", df_areas.shape)\n",
    "print(\"Riesgos:\", df_riesgos.shape, \"Controles:\", df_controles.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ed7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1.1 – Generar calendario diario del escenario STDE (12 semanas) + marca de lunes crítico\n",
    "\n",
    "def generar_calendario(escenario_cfg):\n",
    "    fecha_inicio_str = escenario_cfg[\"fecha_inicio\"]\n",
    "    numero_semanas = escenario_cfg[\"numero_semanas\"]\n",
    "    fecha_lunes_critico_str = escenario_cfg[\"lunes_critico\"][\"fecha\"]\n",
    "\n",
    "    fecha_inicio = date.fromisoformat(fecha_inicio_str)\n",
    "    dias_totales = numero_semanas * 7  # 12 semanas → 84 días (sin lunes crítico)\n",
    "    fecha_lunes_critico = date.fromisoformat(fecha_lunes_critico_str)\n",
    "\n",
    "    registros = []\n",
    "    for i in range(dias_totales):\n",
    "        fecha = fecha_inicio + timedelta(days=i)\n",
    "        semana = (i // 7) + 1  # semana 1..12\n",
    "        dia_semana = fecha.weekday()  # 0 = lunes, 6 = domingo\n",
    "\n",
    "        registros.append(\n",
    "            {\n",
    "                \"id_dia\": i + 1,\n",
    "                \"fecha\": fecha,\n",
    "                \"semana\": semana,\n",
    "                \"dia_semana\": dia_semana,\n",
    "                \"es_lunes_critico\": (fecha == fecha_lunes_critico),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    calendario = pd.DataFrame(registros)\n",
    "    return calendario\n",
    "\n",
    "calendario = generar_calendario(escenario_cfg)\n",
    "print(\"Días calendario:\", len(calendario))\n",
    "calendario.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0514fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1.2 – Generar FDO diario (7 factores) con patrones suaves\n",
    "\n",
    "fdo_factores = fdo_cfg.get(\"factores\", [])\n",
    "\n",
    "# Creamos un índice de factores por id para referencia si se requiere después\n",
    "FDO_IDS = [f[\"id\"] for f in fdo_factores]\n",
    "\n",
    "def generar_fdo_diario(calendario):\n",
    "    registros = []\n",
    "    for _, row in calendario.iterrows():\n",
    "        fecha = row[\"fecha\"]\n",
    "        semana = row[\"semana\"]\n",
    "        id_dia = row[\"id_dia\"]\n",
    "\n",
    "        # Base de variación semanal: degradación leve hacia semana 12\n",
    "        # Normalizamos semana 1..12 a 0..1\n",
    "        t = (semana - 1) / (calendario[\"semana\"].max() - 1)\n",
    "\n",
    "        # Definimos patrones simplificados coherentes con la narrativa:\n",
    "        # - Producción: crece con el tiempo (más presión)\n",
    "        # - Backlog: crece (mantenimiento atrasado)\n",
    "        # - Congestión: crece con producción\n",
    "        # - Fatiga: crece, modulada por día de la semana (más alta al final de la semana)\n",
    "        # - Clima: variación aleatoria suave\n",
    "        # - Dotación: algo decreciente (baja levemente)\n",
    "        # - Variabilidad: aumenta moderadamente\n",
    "        dow = row[\"dia_semana\"]  # 0 lunes, 6 domingo\n",
    "\n",
    "        fdo_produccion = np.clip(0.3 + 0.6 * t + np.random.normal(0, 0.05), 0.0, 1.0)\n",
    "        fdo_backlog = np.clip(0.2 + 0.7 * t + np.random.normal(0, 0.05), 0.0, 1.0)\n",
    "        fdo_congestion = np.clip(0.25 + 0.6 * t + np.random.normal(0, 0.05), 0.0, 1.0)\n",
    "\n",
    "        # Fatiga: más alta jueves-viernes (3,4)\n",
    "        fatiga_semana = 0.2 + 0.6 * t\n",
    "        ajuste_dow = 0.1 if dow in (3, 4) else 0.0\n",
    "        fdo_fatiga = np.clip(fatiga_semana + ajuste_dow + np.random.normal(0, 0.05), 0.0, 1.0)\n",
    "\n",
    "        # Clima: ruido con tendencia leve\n",
    "        fdo_clima = np.clip(0.4 + 0.2 * np.sin(2 * np.pi * t) + np.random.normal(0, 0.1), 0.0, 1.0)\n",
    "\n",
    "        # Dotación: leve caída con el tiempo (renuncias, licencias, etc.)\n",
    "        fdo_dotacion = np.clip(0.9 - 0.3 * t + np.random.normal(0, 0.05), 0.0, 1.0)\n",
    "\n",
    "        # Variabilidad: aumenta hacia el final (más cambios de plan)\n",
    "        fdo_variabilidad = np.clip(0.2 + 0.6 * t + np.random.normal(0, 0.05), 0.0, 1.0)\n",
    "\n",
    "        registros.append(\n",
    "            {\n",
    "                \"id_dia\": id_dia,\n",
    "                \"fecha\": fecha,\n",
    "                \"semana\": semana,\n",
    "                \"fdo_produccion\": fdo_produccion,\n",
    "                \"fdo_backlog\": fdo_backlog,\n",
    "                \"fdo_congestion\": fdo_congestion,\n",
    "                \"fdo_fatiga\": fdo_fatiga,\n",
    "                \"fdo_clima\": fdo_clima,\n",
    "                \"fdo_dotacion\": fdo_dotacion,\n",
    "                \"fdo_variabilidad\": fdo_variabilidad,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df_fdo = pd.DataFrame(registros)\n",
    "    return df_fdo\n",
    "\n",
    "df_fdo_diario = generar_fdo_diario(calendario)\n",
    "print(\"FDO diario generado:\", df_fdo_diario.shape)\n",
    "df_fdo_diario.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c35b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2.1 – Generar trayectorias diarias de criticidad para R01, R02, R03\n",
    "\n",
    "RIESGOS_FOCO = [\"R01\", \"R02\", \"R03\"]\n",
    "\n",
    "def generar_trayectorias_riesgo(calendario):\n",
    "    registros = []\n",
    "    max_semana = calendario[\"semana\"].max()\n",
    "\n",
    "    for _, row in calendario.iterrows():\n",
    "        fecha = row[\"fecha\"]\n",
    "        semana = row[\"semana\"]\n",
    "        id_dia = row[\"id_dia\"]\n",
    "\n",
    "        # Normalización temporal 0..1 sobre las 12 semanas\n",
    "        t = (semana - 1) / (max_semana - 1)\n",
    "\n",
    "        # -------------------------------\n",
    "        # R02 – Degradación acumulada fuerte\n",
    "        # -------------------------------\n",
    "        base_R02 = 0.35 + 0.5 * t  # crece fuertemente hacia el final\n",
    "        ruido_R02 = np.random.normal(0, 0.03)\n",
    "        criticidad_R02 = np.clip(base_R02 + ruido_R02, 0.0, 1.0)\n",
    "\n",
    "        # -------------------------------\n",
    "        # R01 – Controlado pero con señales débiles\n",
    "        # -------------------------------\n",
    "        base_R01 = 0.25 + 0.25 * t  # leve pendiente\n",
    "        ruido_R01 = np.random.normal(0, 0.03)\n",
    "        criticidad_R01 = np.clip(base_R01 + ruido_R01, 0.0, 1.0)\n",
    "\n",
    "        # -------------------------------\n",
    "        # R03 – Estable con variaciones leves\n",
    "        # -------------------------------\n",
    "        base_R03 = 0.2 + 0.15 * t  # leve aumento\n",
    "        # Picos esporádicos: algunos días sube un poco más\n",
    "        pico = 0.1 if random.random() < 0.08 else 0.0\n",
    "        ruido_R03 = np.random.normal(0, 0.03)\n",
    "        criticidad_R03 = np.clip(base_R03 + pico + ruido_R03, 0.0, 1.0)\n",
    "\n",
    "        registros.append(\n",
    "            {\n",
    "                \"id_dia\": id_dia,\n",
    "                \"fecha\": fecha,\n",
    "                \"semana\": semana,\n",
    "                \"criticidad_R01\": criticidad_R01,\n",
    "                \"criticidad_R02\": criticidad_R02,\n",
    "                \"criticidad_R03\": criticidad_R03,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df_tray = pd.DataFrame(registros)\n",
    "    return df_tray\n",
    "\n",
    "df_trayectorias = generar_trayectorias_riesgo(calendario)\n",
    "print(\"Trayectorias generadas:\", df_trayectorias.shape)\n",
    "df_trayectorias.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7187d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2.2 – Trayectoria ponderada global por día y agregados por semana\n",
    "\n",
    "PESOS_RIESGO_GLOBAL = {\n",
    "    \"R01\": 0.25,\n",
    "    \"R02\": 0.5,\n",
    "    \"R03\": 0.25,\n",
    "}\n",
    "\n",
    "def agregar_trayectoria_global(df_tray):\n",
    "    df = df_tray.copy()\n",
    "\n",
    "    df[\"criticidad_global\"] = (\n",
    "        df[\"criticidad_R01\"] * PESOS_RIESGO_GLOBAL[\"R01\"]\n",
    "        + df[\"criticidad_R02\"] * PESOS_RIESGO_GLOBAL[\"R02\"]\n",
    "        + df[\"criticidad_R03\"] * PESOS_RIESGO_GLOBAL[\"R03\"]\n",
    "    )\n",
    "\n",
    "    # Agregados semanales para facilitar gráficos en la demo (medias por semana)\n",
    "    df_semana = (\n",
    "        df.groupby(\"semana\", as_index=False)[\n",
    "            [\n",
    "                \"criticidad_R01\",\n",
    "                \"criticidad_R02\",\n",
    "                \"criticidad_R03\",\n",
    "                \"criticidad_global\",\n",
    "            ]\n",
    "        ]\n",
    "        .mean()\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"criticidad_R01\": \"criticidad_R01_media\",\n",
    "                \"criticidad_R02\": \"criticidad_R02_media\",\n",
    "                \"criticidad_R03\": \"criticidad_R03_media\",\n",
    "                \"criticidad_global\": \"criticidad_global_media\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df, df_semana\n",
    "\n",
    "df_trayectorias, df_trayectorias_semana = agregar_trayectoria_global(df_trayectorias)\n",
    "\n",
    "print(\"df_trayectorias:\", df_trayectorias.shape)\n",
    "print(\"df_trayectorias_semana:\", df_trayectorias_semana.shape)\n",
    "df_trayectorias_semana.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3.1 – Funciones base de probabilidad para eventos diarios STDE v3\n",
    "\n",
    "def base_PD(criticidad):\n",
    "    \"\"\"\n",
    "    HAZARD ~ señales débiles, más frecuentes.\n",
    "    0.5 * criticidad → moderada sensibilidad.\n",
    "    \"\"\"\n",
    "    return np.clip(0.10 + 0.50 * criticidad, 0.0, 0.9)\n",
    "\n",
    "\n",
    "def base_NM(criticidad):\n",
    "    \"\"\"\n",
    "    NMS ~ señales intermedias.\n",
    "    Más fuerte en R02 (alta degradación).\n",
    "    \"\"\"\n",
    "    return np.clip(0.02 + 0.35 * criticidad, 0.0, 0.7)\n",
    "\n",
    "\n",
    "def base_IM(criticidad):\n",
    "    \"\"\"\n",
    "    IMEN (lesión leve) ~ baja probabilidad, solo casos severos.\n",
    "    \"\"\"\n",
    "    return np.clip(0.005 + 0.08 * criticidad, 0.0, 0.25)\n",
    "\n",
    "\n",
    "def modular_por_fdo(prob, fdo_row):\n",
    "    \"\"\"\n",
    "    Ajusta la probabilidad con los FDO diarios.\n",
    "    Reglas STDE v3:\n",
    "      - producción, congestión y fatiga aumentan prob. de eventos\n",
    "      - dotación baja → aumenta riesgo\n",
    "      - clima extremo → altera probabilidad\n",
    "    \"\"\"\n",
    "    factor = (\n",
    "        1.0\n",
    "        + 0.30 * fdo_row[\"fdo_produccion\"]\n",
    "        + 0.20 * fdo_row[\"fdo_congestion\"]\n",
    "        + 0.20 * fdo_row[\"fdo_fatiga\"]\n",
    "        + 0.10 * (1.0 - fdo_row[\"fdo]()_*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb82c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3.1b – Versión corregida de modular_por_fdo (redefine solo esta función)\n",
    "\n",
    "def modular_por_fdo(prob, fdo_row):\n",
    "    \"\"\"\n",
    "    Ajusta la probabilidad con los FDO diarios.\n",
    "    Reglas STDE v3:\n",
    "      - producción, congestión y fatiga aumentan prob. de eventos\n",
    "      - dotación baja → aumenta riesgo\n",
    "      - clima extremo → altera probabilidad\n",
    "    \"\"\"\n",
    "    factor = (\n",
    "        1.0\n",
    "        + 0.30 * fdo_row[\"fdo_produccion\"]\n",
    "        + 0.20 * fdo_row[\"fdo_congestion\"]\n",
    "        + 0.20 * fdo_row[\"fdo_fatiga\"]\n",
    "        + 0.10 * (1.0 - fdo_row[\"fdo_dotacion\"])   # menos dotación → más riesgo\n",
    "        + 0.10 * abs(fdo_row[\"fdo_clima\"] - 0.5)   # clima muy bueno o muy malo altera el riesgo\n",
    "    )\n",
    "\n",
    "    prob_mod = np.clip(prob * factor, 0.0, 0.99)\n",
    "    return prob_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3.2 – Generar eventos diarios (HAZARD / NMS / IMEN) coherentes con OMS v3\n",
    "\n",
    "# Extraer mapeo riesgo_por_area\n",
    "riesgo_por_area = mapeos_operacionales.get(\"riesgo_por_area\", {})\n",
    "\n",
    "# Preprocesar roles y tareas por área\n",
    "roles_por_area = df_roles.groupby(\"area_operacional_id\")[\"id_rol\"].apply(list).to_dict()\n",
    "tareas_por_area = df_tareas.groupby(\"area_operacional_id\")[\"id_tarea\"].apply(list).to_dict()\n",
    "\n",
    "\n",
    "def elegir_riesgo_area(area_id):\n",
    "    \"\"\"\n",
    "    Selecciona un riesgo según los pesos definidos en la OMS.\n",
    "    \"\"\"\n",
    "    lista = riesgo_por_area.get(area_id, [])\n",
    "    if not lista:\n",
    "        return None\n",
    "\n",
    "    riesgos = [x[\"riesgo_id\"] for x in lista]\n",
    "    pesos = [x[\"peso_relativo\"] for x in lista]\n",
    "    return random.choices(riesgos, weights=pesos, k=1)[0]\n",
    "\n",
    "\n",
    "def asignar_tipo_incidente(prob_pd, prob_nm, prob_im):\n",
    "    \"\"\"\n",
    "    Según probabilidades ajustadas, asigna el tipo de incidente narrativo:\n",
    "    HAZARD, NMS, IMEN.\n",
    "    \"\"\"\n",
    "    r = random.random()\n",
    "    if r < prob_im:\n",
    "        return \"IMEN\"\n",
    "    elif r < (prob_nm + prob_im):\n",
    "        return \"NMS\"\n",
    "    elif r < (prob_pd + prob_nm + prob_im):\n",
    "        return \"HAZARD\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def mapear_tipo_formal(tipo_narrativo):\n",
    "    \"\"\"\n",
    "    Mapea narrativa → formal según OMS v3:\n",
    "        HAZARD → INMI\n",
    "        NMS    → INMI\n",
    "        IMEN   → ILEV\n",
    "    \"\"\"\n",
    "    if tipo_narrativo in [\"HAZARD\", \"NMS\"]:\n",
    "        return \"INMI\"\n",
    "    if tipo_narrativo == \"IMEN\":\n",
    "        return \"ILEV\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def generar_eventos_v3(calendario, df_tray, df_fdo, oms):\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    for _, row in calendario.iterrows():\n",
    "        fecha = row[\"fecha\"]\n",
    "        semana = row[\"semana\"]\n",
    "        id_dia = row[\"id_dia\"]\n",
    "\n",
    "        # Filtrar FDO y trayectorias del día\n",
    "        fdo_row = df_fdo[df_fdo[\"id_dia\"] == id_dia].iloc[0]\n",
    "        tray_row = df_tray[df_tray[\"id_dia\"] == id_dia].iloc[0]\n",
    "\n",
    "        for _, area_row in df_areas.iterrows():\n",
    "            area_id = area_row[\"id_area\"]\n",
    "            \n",
    "            # 1. Seleccionar el riesgo dominante del área\n",
    "            riesgo_id = elegir_riesgo_area(area_id)\n",
    "            if riesgo_id not in [\"R01\", \"R02\", \"R03\"]:\n",
    "                continue  # solo modelamos 3 riesgos\n",
    "\n",
    "            criticidad = tray_row[f\"criticidad_{riesgo_id}\"]\n",
    "\n",
    "            # 2. Probabilidades base\n",
    "            prob_pd = base_PD(criticidad)\n",
    "            prob_nm = base_NM(criticidad)\n",
    "            prob_im = base_IM(criticidad)\n",
    "\n",
    "            # 3. Modulación FDO\n",
    "            prob_pd = modular_por_fdo(prob_pd, fdo_row)\n",
    "            prob_nm = modular_por_fdo(prob_nm, fdo_row)\n",
    "            prob_im = modular_por_fdo(prob_im, fdo_row)\n",
    "\n",
    "            # 4. Determinar si ocurre evento\n",
    "            tipo_narrativo = asignar_tipo_incidente(prob_pd, prob_nm, prob_im)\n",
    "            if tipo_narrativo is None:\n",
    "                continue\n",
    "\n",
    "            tipo_formal = mapear_tipo_formal(tipo_narrativo)\n",
    "\n",
    "            # 5. Rol y tarea coherentes\n",
    "            rol_ids = roles_por_area.get(area_id, [])\n",
    "            tarea_ids = tareas_por_area.get(area_id, [])\n",
    "            rol_id = random.choice(rol_ids) if rol_ids else None\n",
    "            tarea_id = random.choice(tarea_ids) if tarea_ids else None\n",
    "\n",
    "            registros.append({\n",
    "                \"id_evento\": f\"EVT_{id_dia}_{area_id}_{riesgo_id}\",\n",
    "                \"fecha\": fecha,\n",
    "                \"semana\": semana,\n",
    "                \"id_area\": area_id,\n",
    "                \"rol_id\": rol_id,\n",
    "                \"tarea_id\": tarea_id,\n",
    "                \"riesgo_id\": riesgo_id,\n",
    "                \"tipo_narrativo\": tipo_narrativo,  # HAZARD / NMS / IMEN\n",
    "                \"tipo_formal\": tipo_formal,        # INMI / ILEV\n",
    "                \"criticidad\": criticidad,\n",
    "                \"prob_pd\": prob_pd,\n",
    "                \"prob_nm\": prob_nm,\n",
    "                \"prob_im\": prob_im,\n",
    "                \"es_lunes_critico\": False,\n",
    "            })\n",
    "\n",
    "    df_eventos = pd.DataFrame(registros)\n",
    "    return df_eventos\n",
    "\n",
    "\n",
    "df_eventos = generar_eventos_v3(calendario, df_trayectorias, df_fdo_diario, oms)\n",
    "print(\"Eventos generados:\", df_eventos.shape)\n",
    "df_eventos.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed33a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3.3 – Inyección del lunes crítico (evento compuesto real)\n",
    "\n",
    "def inyectar_lunes_critico(df_eventos, calendario):\n",
    "    \"\"\"\n",
    "    Inserta el lunes crítico como un EVENTO COMPUESTO:\n",
    "    - 1 registro maestro (LC_EVT_00)\n",
    "    - 2 sub-eventos NMS asociados (R01 y R02)\n",
    "    Usando EXACTAMENTE la narrativa del archivo 'Evento lunes critico.txt'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fecha y semana del LC\n",
    "    fecha_lc = calendario[calendario[\"es_lunes_critico\"] == True][\"fecha\"].iloc[0]\n",
    "    semana_lc = calendario[calendario[\"es_lunes_critico\"] == True][\"semana\"].iloc[0]\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    # =============================================================\n",
    "    # EVENTO MAESTRO — Evento compuesto\n",
    "    # =============================================================\n",
    "    registros.append({\n",
    "        \"id_evento\": \"LC_EVT_00\",\n",
    "        \"id_evento_compuesto\": None,\n",
    "        \"fecha\": fecha_lc,\n",
    "        \"semana\": semana_lc,\n",
    "        \"id_area\": \"MRA\",\n",
    "        \"rol_id\": None,\n",
    "        \"tarea_id\": None,\n",
    "\n",
    "        \"riesgo_id\": None,\n",
    "        \"tipo_narrativo\": \"NMS_COMPUESTO\",\n",
    "        \"tipo_formal\": \"INMI\",\n",
    "\n",
    "        \"criticidad\": 0.92,  # outlier realista\n",
    "        \"prob_pd\": None,\n",
    "        \"prob_nm\": None,\n",
    "        \"prob_im\": None,\n",
    "        \"es_lunes_critico\": True,\n",
    "\n",
    "        # NARRATIVA EXACTA\n",
    "        \"descripcion_evento\": (\n",
    "            \"Durante la inspección rutinaria en un andamio móvil, un trabajador perdió parcialmente \"\n",
    "            \"el equilibrio por una irregularidad en la plataforma y, en la maniobra, también se le \"\n",
    "            \"cayó una llave desde altura. El arnés detuvo la caída y la herramienta no impactó \"\n",
    "            \"a ninguna persona.\"\n",
    "        ),\n",
    "\n",
    "        \"evento_principal_ocurrido\": (\n",
    "            \"Pérdida de equilibrio en andamio que activa simultáneamente caída detenida (R01) \"\n",
    "            \"y caída de objeto (R02).\"\n",
    "        ),\n",
    "\n",
    "        \"control_critico_relacionado\": None,\n",
    "        \"potencial_consecuencia_severidad\": None,\n",
    "    })\n",
    "\n",
    "    # =============================================================\n",
    "    # SUB-EVENTO R01 — Caída detenida por arnés\n",
    "    # =============================================================\n",
    "    registros.append({\n",
    "        \"id_evento\": \"LC_EVT_01\",\n",
    "        \"id_evento_compuesto\": \"LC_EVT_00\",\n",
    "        \"fecha\": fecha_lc,\n",
    "        \"semana\": semana_lc,\n",
    "        \"id_area\": \"MRA\",\n",
    "        \"rol_id\": None,\n",
    "        \"tarea_id\": None,\n",
    "\n",
    "        \"riesgo_id\": \"R01\",\n",
    "        \"tipo_narrativo\": \"NMS\",\n",
    "        \"tipo_formal\": \"INMI\",\n",
    "\n",
    "        \"criticidad\": 0.90,\n",
    "        \"prob_pd\": None,\n",
    "        \"prob_nm\": None,\n",
    "        \"prob_im\": None,\n",
    "        \"es_lunes_critico\": True,\n",
    "\n",
    "        \"descripcion_evento\": (\n",
    "            \"Trabajador pierde equilibrio en andamio. El arnés de seguridad activa el sistema \"\n",
    "            \"de detención evitando consecuencias mayores.\"\n",
    "        ),\n",
    "\n",
    "        \"evento_principal_ocurrido\": \"Caída detenida por el arnés.\",\n",
    "        \"control_critico_relacionado\": \"R01CC01\",\n",
    "        \"potencial_consecuencia_severidad\": \"SEV4\",\n",
    "    })\n",
    "\n",
    "    # =============================================================\n",
    "    # SUB-EVENTO R02 — Caída de llave sin impacto\n",
    "    # =============================================================\n",
    "    registros.append({\n",
    "        \"id_evento\": \"LC_EVT_02\",\n",
    "        \"id_evento_compuesto\": \"LC_EVT_00\",\n",
    "        \"fecha\": fecha_lc,\n",
    "        \"semana\": semana_lc,\n",
    "        \"id_area\": \"MRA\",\n",
    "        \"rol_id\": None,\n",
    "        \"tarea_id\": None,\n",
    "\n",
    "        \"riesgo_id\": \"R02\",\n",
    "        \"tipo_narrativo\": \"NMS\",\n",
    "        \"tipo_formal\": \"INMI\",\n",
    "\n",
    "        \"criticidad\": 0.85,\n",
    "        \"prob_pd\": None,\n",
    "        \"prob_nm\": None,\n",
    "        \"prob_im\": None,\n",
    "        \"es_lunes_critico\": True,\n",
    "\n",
    "        \"descripcion_evento\": (\n",
    "            \"Durante la pérdida de equilibrio, una llave cayó desde ~2.5 metros sin impactar \"\n",
    "            \"a personas, registrándose como Near Miss.\"\n",
    "        ),\n",
    "\n",
    "        \"evento_principal_ocurrido\": \"Caída de objeto desde altura.\",\n",
    "        \"control_critico_relacionado\": \"R02CC03\",\n",
    "        \"potencial_consecuencia_severidad\": \"SEV3\",\n",
    "    })\n",
    "\n",
    "    # =============================================================\n",
    "    # Integrar con df_eventos existente\n",
    "    # =============================================================\n",
    "    df_lc = pd.DataFrame(registros)\n",
    "    df_final = pd.concat([df_eventos, df_lc], ignore_index=True)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "\n",
    "# Aplicar inyección\n",
    "df_eventos = inyectar_lunes_critico(df_eventos, calendario)\n",
    "\n",
    "print(\"Eventos totales con lunes crítico:\", df_eventos.shape)\n",
    "df_eventos[df_eventos[\"es_lunes_critico\"] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4faa564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4.1 – Generación de OPG (ruido operacional)\n",
    "\n",
    "# Tasas por área (según OMS v3 - regla de ruido operacional)\n",
    "tasa_opg_area = {\n",
    "    \"MRA\": (2, 4),\n",
    "    \"PLC\": (1, 3),\n",
    "    \"TRN\": (1, 2),\n",
    "    \"TME\": (1, 2),\n",
    "}\n",
    "\n",
    "def generar_opg(calendario, df_fdo, df_tray, df_roles, df_tareas):\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    for _, row in calendario.iterrows():\n",
    "        fecha = row[\"fecha\"]\n",
    "        semana = row[\"semana\"]\n",
    "        id_dia = row[\"id_dia\"]\n",
    "\n",
    "        fdo_row = df_fdo[df_fdo[\"id_dia\"] == id_dia].iloc[0]\n",
    "        tray_row = df_tray[df_tray[\"id_dia\"] == id_dia].iloc[0]\n",
    "\n",
    "        for _, area in df_areas.iterrows():\n",
    "            area_id = area[\"id_area\"]\n",
    "\n",
    "            # 1. Cuántas OPG generar hoy\n",
    "            low, high = tasa_opg_area.get(area_id, (1, 2))\n",
    "            n_opg = random.randint(low, high)\n",
    "\n",
    "            # 2. Riesgo dominante por área → afecta positividad/negatividad\n",
    "            try:\n",
    "                riesgo_dom = elegir_riesgo_area(area_id)\n",
    "            except:\n",
    "                riesgo_dom = None\n",
    "\n",
    "            criticidad = tray_row[f\"criticidad_{riesgo_dom}\"] if riesgo_dom in [\"R01\",\"R02\",\"R03\"] else 0.2\n",
    "\n",
    "            for _ in range(n_opg):\n",
    "\n",
    "                rol_id = random.choice(roles_por_area.get(area_id, [None]))\n",
    "                tarea_id = random.choice(tareas_por_area.get(area_id, [None]))\n",
    "\n",
    "                # Probabilidad de OPG negativa (OPG–)\n",
    "                p_neg = (\n",
    "                    0.10\n",
    "                    + 0.30 * fdo_row[\"fdo_fatiga\"]\n",
    "                    + 0.20 * fdo_row[\"fdo_congestion\"]\n",
    "                    + 0.30 * criticidad\n",
    "                )\n",
    "\n",
    "                estado = \"OPG-\" if random.random() < p_neg else \"OPG+\"\n",
    "\n",
    "                registros.append({\n",
    "                    \"id_observacion\": f\"OPG_{id_dia}_{area_id}_{random.randint(1000,9999)}\",\n",
    "                    \"fecha\": fecha,\n",
    "                    \"semana\": semana,\n",
    "                    \"id_area\": area_id,\n",
    "                    \"rol_observador_id\": rol_id,\n",
    "                    \"rol_observado_id\": None,\n",
    "                    \"tarea_id\": tarea_id,\n",
    "                    \"tipo_observacion\": \"OPG\",\n",
    "                    \"estado\": estado,\n",
    "                    \"riesgo_id\": riesgo_dom,\n",
    "                    \"is_control_critico\": False,\n",
    "                    \"control_critico_id\": None,\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(registros)\n",
    "\n",
    "\n",
    "df_opg = generar_opg(calendario, df_fdo_diario, df_trayectorias, df_roles, df_tareas)\n",
    "print(\"OPG generadas:\", df_opg.shape)\n",
    "df_opg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a90b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4.2 – Generación de OCC reactivas\n",
    "\n",
    "# Diccionario de controles críticos por riesgo\n",
    "controles_por_riesgo = df_controles.groupby(\"riesgo_asociado\")[\"id\"].apply(list).to_dict()\n",
    "\n",
    "def generar_occ(df_eventos, calendario, df_fdo):\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    for _, ev in df_eventos.iterrows():\n",
    "\n",
    "        if ev[\"tipo_narrativo\"] not in [\"HAZARD\", \"NMS\", \"IMEN\"]:\n",
    "            continue\n",
    "\n",
    "        fecha = ev[\"fecha\"]\n",
    "        semana = ev[\"semana\"]\n",
    "        riesgo_id = ev[\"riesgo_id\"]\n",
    "        id_dia = calendario[calendario[\"fecha\"] == fecha][\"id_dia\"].iloc[0]\n",
    "\n",
    "        fdo_row = df_fdo[df_fdo[\"id_dia\"] == id_dia].iloc[0]\n",
    "\n",
    "        # 1 o 2 OCC por evento\n",
    "        n_occ = random.randint(1, 2)\n",
    "\n",
    "        # picks del área → roles y tareas\n",
    "        area_id = ev[\"id_area\"]\n",
    "        rol_id = random.choice(roles_por_area.get(area_id, [None]))\n",
    "        tarea_id = random.choice(tareas_por_area.get(area_id, [None]))\n",
    "\n",
    "        # control crítico asociado\n",
    "        posibles_controles = controles_por_riesgo.get(riesgo_id, [])\n",
    "        control_usado = random.choice(posibles_controles) if posibles_controles else None\n",
    "\n",
    "        for _ in range(n_occ):\n",
    "\n",
    "            # Probabilidad de OCC negativo\n",
    "            p_neg = (\n",
    "                0.15\n",
    "                + 0.25 * fdo_row[\"fdo_fatiga\"]\n",
    "                + 0.20 * fdo_row[\"fdo_congestion\"]\n",
    "                + 0.30 * ev[\"criticidad\"]\n",
    "            )\n",
    "\n",
    "            # EXCEPCIÓN: Lunes crítico R01 → OCC+ explícito\n",
    "            if ev.get(\"es_lunes_critico\") and riesgo_id == \"R01\":\n",
    "                estado = \"OCC+\"\n",
    "            else:\n",
    "                estado = \"OCC-\" if random.random() < p_neg else \"OCC+\"\n",
    "\n",
    "            registros.append({\n",
    "                \"id_observacion\": f\"OCC_{ev['id_evento']}_{random.randint(1000,9999)}\",\n",
    "                \"fecha\": fecha,\n",
    "                \"semana\": semana,\n",
    "                \"id_area\": area_id,\n",
    "                \"rol_observador_id\": rol_id,\n",
    "                \"rol_observado_id\": None,\n",
    "                \"tarea_id\": tarea_id,\n",
    "                \"tipo_observacion\": \"OCC\",\n",
    "                \"estado\": estado,\n",
    "                \"riesgo_id\": riesgo_id,\n",
    "                \"is_control_critico\": True,\n",
    "                \"control_critico_id\": control_usado,\n",
    "                \"id_evento_origen\": ev[\"id_evento\"],\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(registros)\n",
    "\n",
    "\n",
    "df_occ = generar_occ(df_eventos, calendario, df_fdo_diario)\n",
    "print(\"OCC generadas:\", df_occ.shape)\n",
    "df_occ.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4.3 – Consolidar observaciones OPG + OCC\n",
    "\n",
    "df_observaciones = pd.concat([df_opg, df_occ], ignore_index=True)\n",
    "print(\"Total observaciones:\", df_observaciones.shape)\n",
    "df_observaciones.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5.1 – Auditorías AUF reactivas\n",
    "\n",
    "def generar_auditorias_reactivas(df_eventos, df_observaciones, df_fdo, calendario):\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1. AUF por Near Miss severo (SEV3 o SEV4)\n",
    "    # ------------------------------------------------------------------\n",
    "    df_nms = df_eventos[\n",
    "        (df_eventos[\"tipo_narrativo\"] == \"NMS\") &\n",
    "        (df_eventos[\"potencial_consecuencia_severidad\"].isin([\"SEV3\", \"SEV4\"]))\n",
    "    ]\n",
    "\n",
    "    for _, ev in df_nms.iterrows():\n",
    "        fecha_ev = ev[\"fecha\"]\n",
    "\n",
    "        # AUF programada máximo 48 horas después\n",
    "        fecha_auf = fecha_ev + timedelta(days=random.choice([1, 2]))\n",
    "        semana_auf = calendario[calendario[\"fecha\"] == fecha_auf][\"semana\"]\n",
    "        semana_auf = int(semana_auf.iloc[0]) if not semana_auf.empty else ev[\"semana\"]\n",
    "\n",
    "        registros.append({\n",
    "            \"id_auditoria\": f\"AUF_NMS_{ev['id_evento']}\",\n",
    "            \"fecha\": fecha_auf,\n",
    "            \"semana\": semana_auf,\n",
    "            \"id_area\": ev[\"id_area\"],\n",
    "            \"tipo_auditoria\": \"AUF\",\n",
    "            \"origen\": \"post_nm\",\n",
    "            \"riesgo_focal\": ev[\"riesgo_id\"],\n",
    "            \"id_evento_origen\": ev[\"id_evento\"],\n",
    "        })\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2. AUF por falla de control crítico (OCC−)\n",
    "    # ------------------------------------------------------------------\n",
    "    df_occ_neg = df_observaciones[\n",
    "        (df_observaciones[\"tipo_observacion\"] == \"OCC\") &\n",
    "        (df_observaciones[\"estado\"] == \"OCC-\")\n",
    "    ]\n",
    "\n",
    "    for _, obs in df_occ_neg.iterrows():\n",
    "        fecha_obs = obs[\"fecha\"]\n",
    "        semana_obs = obs[\"semana\"]\n",
    "\n",
    "        registros.append({\n",
    "            \"id_auditoria\": f\"AUF_OCCNEG_{obs['id_observacion']}\",\n",
    "            \"fecha\": fecha_obs,\n",
    "            \"semana\": semana_obs,\n",
    "            \"id_area\": obs[\"id_area\"],\n",
    "            \"tipo_auditoria\": \"AUF\",\n",
    "            \"origen\": \"post_incidente\",\n",
    "            \"riesgo_focal\": obs[\"riesgo_id\"],\n",
    "            \"id_evento_origen\": obs.get(\"id_evento_origen\"),\n",
    "        })\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3. AUF por señales PD críticas dos días seguidos\n",
    "    #    (criticidad diaria > 0.75 por dos días consecutivos)\n",
    "    # ------------------------------------------------------------------\n",
    "    df_fdo_sorted = df_fdo.sort_values(\"id_dia\")\n",
    "\n",
    "    for riesgo in [\"R01\", \"R02\", \"R03\"]:\n",
    "        criticidades = df_eventos.groupby(\"fecha\")[\"criticidad\"].mean()\n",
    "\n",
    "        fechas = list(criticidades.index)\n",
    "        for i in range(len(fechas) - 1):\n",
    "            if criticidades.iloc[i] > 0.75 and criticidades.iloc[i + 1] > 0.75:\n",
    "\n",
    "                fecha_auf = fechas[i + 1]\n",
    "                semana_auf = calendario[calendario[\"fecha\"] == fecha_auf][\"semana\"].iloc[0]\n",
    "\n",
    "                registros.append({\n",
    "                    \"id_auditoria\": f\"AUF_PDCRIT_{riesgo}_{i}\",\n",
    "                    \"fecha\": fecha_auf,\n",
    "                    \"semana\": semana_auf,\n",
    "                    \"id_area\": \"MRA\",\n",
    "                    \"tipo_auditoria\": \"AUF\",\n",
    "                    \"origen\": \"post_pd_critico\",\n",
    "                    \"riesgo_focal\": riesgo,\n",
    "                    \"id_evento_origen\": None,\n",
    "                })\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 4. AUF por el lunes crítico (forzadas por narrativa)\n",
    "    # ------------------------------------------------------------------\n",
    "    df_lc = df_eventos[df_eventos[\"es_lunes_critico\"] == True]\n",
    "\n",
    "    for _, ev in df_lc.iterrows():\n",
    "        registros.append({\n",
    "            \"id_auditoria\": f\"AUF_LC_{ev['id_evento']}\",\n",
    "            \"fecha\": ev[\"fecha\"],\n",
    "            \"semana\": ev[\"semana\"],\n",
    "            \"id_area\": ev[\"id_area\"],\n",
    "            \"tipo_auditoria\": \"AUF\",\n",
    "            \"origen\": \"post_nm_compuesto\",\n",
    "            \"riesgo_focal\": ev[\"riesgo_id\"],\n",
    "            \"id_evento_origen\": ev[\"id_evento\"],\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(registros)\n",
    "\n",
    "\n",
    "df_auf_reactivas = generar_auditorias_reactivas(df_eventos, df_observaciones, df_fdo_diario, calendario)\n",
    "print(\"AUF reactivas generadas:\", df_auf_reactivas.shape)\n",
    "df_auf_reactivas.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5.2 – Auditorías AUF planificadas (cierre de mes)\n",
    "\n",
    "def generar_auditorias_planificadas(calendario, df_areas):\n",
    "\n",
    "    registros = []\n",
    "    meses = calendario[\"fecha\"].dt.month.unique()\n",
    "\n",
    "    for mes in meses:\n",
    "        ultimo_dia_mes = calendario[calendario[\"fecha\"].dt.month == mes][\"fecha\"].max()\n",
    "        semana_mes = calendario[calendario[\"fecha\"] == ultimo_dia_mes][\"semana\"].iloc[0]\n",
    "\n",
    "        for _, area in df_areas.iterrows():\n",
    "\n",
    "            registros.append({\n",
    "                \"id_auditoria\": f\"AUF_PLAN_{area['id_area']}_{mes}\",\n",
    "                \"fecha\": ultimo_dia_mes,\n",
    "                \"semana\": semana_mes,\n",
    "                \"id_area\": area[\"id_area\"],\n",
    "                \"tipo_auditoria\": \"AUF\",\n",
    "                \"origen\": \"cierre_mes\",\n",
    "                \"riesgo_focal\": None,\n",
    "                \"id_evento_origen\": None,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(registros)\n",
    "\n",
    "\n",
    "df_auf_planificadas = generar_auditorias_planificadas(calendario, df_areas)\n",
    "print(\"AUF planificadas:\", df_auf_planificadas.shape)\n",
    "df_auf_planificadas.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17824baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5.3 – Consolidación AUF reactivas + planificadas\n",
    "\n",
    "df_auditorias = pd.concat(\n",
    "    [df_auf_reactivas, df_auf_planificadas],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "print(\"Total auditorías generadas:\", df_auditorias.shape)\n",
    "df_auditorias.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.1 – Cargar modelo proactivo v4.4\n",
    "\n",
    "df_proactivo = pd.read_csv(PATH_PROACTIVO)\n",
    "\n",
    "# Validación rápida\n",
    "print(\"Proactivo v4.4 cargado:\", df_proactivo.shape)\n",
    "df_proactivo.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b85d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.2 – Calcular thresholds por semana y riesgo\n",
    "\n",
    "def calcular_thresholds(df_proactivo):\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    for semana in sorted(df_proactivo[\"semana_id\"].unique()):\n",
    "        df_sem = df_proactivo[df_proactivo[\"semana_id\"] == semana]\n",
    "\n",
    "        scores = df_sem[\"score_proactivo\"].values\n",
    "\n",
    "        # Thresholds basados en percentiles (modelo real)\n",
    "        thr_alerta  = np.round(np.percentile(scores, 60), 2)\n",
    "        thr_critico = np.round(np.percentile(scores, 80), 2)\n",
    "\n",
    "        for _, row in df_sem.iterrows():\n",
    "            registros.append({\n",
    "                \"semana_id\": semana,\n",
    "                \"riesgo_id\": row[\"riesgo_id\"],\n",
    "                \"score_proactivo\": row[\"score_proactivo\"],\n",
    "                \"rank_proactivo\": row[\"rank_proactivo\"],\n",
    "                \"threshold_alerta\": thr_alerta,\n",
    "                \"threshold_critico\": thr_critico\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(registros)\n",
    "\n",
    "\n",
    "df_proactivo_thresholds = calcular_thresholds(df_proactivo)\n",
    "print(\"Thresholds generados:\", df_proactivo_thresholds.shape)\n",
    "df_proactivo_thresholds.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a634ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.3 – Comparar trayectorias reales vs modelo proactivo\n",
    "\n",
    "# 1. Agregar criticidad semanal real (STDE)\n",
    "df_tray_sem = (\n",
    "    df_trayectorias\n",
    "    .groupby(\"semana\")[[\"criticidad_R01\",\"criticidad_R02\",\"criticidad_R03\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"semana\":\"semana_id\"})\n",
    ")\n",
    "\n",
    "# 2. Agregar thresholds semanales\n",
    "df_compare = df_proactivo_thresholds.merge(df_tray_sem, on=\"semana_id\", how=\"left\")\n",
    "\n",
    "# 3. Filtrar solo los riesgos modelados STDE v3\n",
    "df_compare_stde = df_compare[df_compare[\"riesgo_id\"].isin([\"R01\",\"R02\",\"R03\"])]\n",
    "\n",
    "# Mostrar evidencia clara de desalineación\n",
    "df_compare_stde_sorted = df_compare_stde.sort_values([\"semana_id\",\"rank_proactivo\"])\n",
    "\n",
    "df_compare_stde_sorted.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.4 – Señales individuales por riesgo y semana (base para índice K9)\n",
    "\n",
    "RIESGOS_FOCO = [\"R01\", \"R02\", \"R03\"]\n",
    "\n",
    "def construir_senales_riesgo_semana(\n",
    "    df_trayectorias,\n",
    "    df_eventos,\n",
    "    df_observaciones,\n",
    "    df_auditorias,\n",
    "    df_fdo\n",
    "):\n",
    "    # 1) Criticidad semanal por riesgo (desde df_trayectorias)\n",
    "    df_tray_sem = (\n",
    "        df_trayectorias\n",
    "        .groupby(\"semana\")[[\"criticidad_R01\", \"criticidad_R02\", \"criticidad_R03\"]]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"semana\": \"semana_id\"})\n",
    "    )\n",
    "\n",
    "    # 2) Eventos por tipo narrativo\n",
    "    df_ev_agg = (\n",
    "        df_eventos\n",
    "        .dropna(subset=[\"riesgo_id\"])\n",
    "        .groupby([\"semana\", \"riesgo_id\", \"tipo_narrativo\"])\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "        .reset_index()\n",
    "    )\n",
    "    # aseguremos columnas\n",
    "    for col in [\"HAZARD\", \"NMS\", \"IMEN\"]:\n",
    "        if col not in df_ev_agg.columns:\n",
    "            df_ev_agg[col] = 0\n",
    "    df_ev_agg = df_ev_agg.rename(columns={\"semana\": \"semana_id\"})\n",
    "\n",
    "    # 3) Observaciones OPG / OCC por estado\n",
    "    df_obs_agg = (\n",
    "        df_observaciones\n",
    "        .dropna(subset=[\"riesgo_id\"])\n",
    "        .groupby([\"semana\", \"riesgo_id\", \"tipo_observacion\", \"estado\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"n\")\n",
    "    )\n",
    "\n",
    "    def contar_obs(tipo, estado):\n",
    "        df_tmp = df_obs_agg[\n",
    "            (df_obs_agg[\"tipo_observacion\"] == tipo)\n",
    "            & (df_obs_agg[\"estado\"] == estado)\n",
    "        ]\n",
    "        df_tmp = df_tmp.groupby([\"semana\", \"riesgo_id\"])[\"n\"].sum().reset_index()\n",
    "        df_tmp = df_tmp.rename(columns={\"n\": f\"n_{tipo}_{estado}\"})\n",
    "        return df_tmp\n",
    "\n",
    "    df_opg_pos = contar_obs(\"OPG\", \"OPG+\")\n",
    "    df_opg_neg = contar_obs(\"OPG\", \"OPG-\")\n",
    "    df_occ_pos = contar_obs(\"OCC\", \"OCC+\")\n",
    "    df_occ_neg = contar_obs(\"OCC\", \"OCC-\")\n",
    "\n",
    "    # Merge de observaciones\n",
    "    df_obs_merge = df_opg_pos.merge(df_opg_neg, on=[\"semana\", \"riesgo_id\"], how=\"outer\")\n",
    "    df_obs_merge = df_obs_merge.merge(df_occ_pos, on=[\"semana\", \"riesgo_id\"], how=\"outer\")\n",
    "    df_obs_merge = df_obs_merge.merge(df_occ_neg, on=[\"semana\", \"riesgo_id\"], how=\"outer\")\n",
    "    df_obs_merge = df_obs_merge.fillna(0)\n",
    "    df_obs_merge = df_obs_merge.rename(columns={\"semana\": \"semana_id\"})\n",
    "\n",
    "    # 4) Auditorías AUF por riesgo/semana\n",
    "    df_aud_agg = (\n",
    "        df_auditorias\n",
    "        .dropna(subset=[\"riesgo_focal\"])\n",
    "        .groupby([\"semana\", \"riesgo_focal\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"n_auf\")\n",
    "        .rename(columns={\"semana\": \"semana_id\", \"riesgo_focal\": \"riesgo_id\"})\n",
    "    )\n",
    "\n",
    "    # 5) FDO contextual semanal (mismo valor para todos los riesgos, pero útil para gráficas)\n",
    "    df_fdo_sem = (\n",
    "        df_fdo\n",
    "        .groupby(\"semana\")[[\n",
    "            \"fdo_produccion\",\n",
    "            \"fdo_backlog\",\n",
    "            \"fdo_congestion\",\n",
    "            \"fdo_fatiga\",\n",
    "            \"fdo_clima\",\n",
    "            \"fdo_dotacion\",\n",
    "            \"fdo_variabilidad\",\n",
    "        ]]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"semana\": \"semana_id\"})\n",
    "    )\n",
    "    df_fdo_sem[\"fdo_contexto\"] = (\n",
    "        0.25 * df_fdo_sem[\"fdo_produccion\"]\n",
    "        + 0.20 * df_fdo_sem[\"fdo_backlog\"]\n",
    "        + 0.20 * df_fdo_sem[\"fdo_congestion\"]\n",
    "        + 0.20 * df_fdo_sem[\"fdo_fatiga\"]\n",
    "        + 0.15 * (1.0 - df_fdo_sem[\"fdo_dotacion\"])\n",
    "    )\n",
    "\n",
    "    # 6) Construir tabla final por semana x riesgo\n",
    "    registros = []\n",
    "    for semana in sorted(df_tray_sem[\"semana_id\"].unique()):\n",
    "        for riesgo in RIESGOS_FOCO:\n",
    "            row_tray = df_tray_sem[df_tray_sem[\"semana_id\"] == semana].iloc[0]\n",
    "            crit_col = f\"criticidad_{riesgo}_media\"\n",
    "            if crit_col not in row_tray.index:\n",
    "                # renombramos una sola vez: criticidad_R01 -> criticidad_R01_media, etc.\n",
    "                pass\n",
    "\n",
    "            criticidad = row_tray[f\"criticidad_{riesgo}\"]\n",
    "\n",
    "            # Eventos\n",
    "            row_ev = df_ev_agg[\n",
    "                (df_ev_agg[\"semana_id\"] == semana) & (df_ev_agg[\"riesgo_id\"] == riesgo)\n",
    "            ]\n",
    "            if not row_ev.empty:\n",
    "                n_hazard = int(row_ev[\"HAZARD\"].iloc[0])\n",
    "                n_nms = int(row_ev[\"NMS\"].iloc[0])\n",
    "                n_imen = int(row_ev[\"IMEN\"].iloc[0])\n",
    "            else:\n",
    "                n_hazard = n_nms = n_imen = 0\n",
    "\n",
    "            # Observaciones\n",
    "            row_obs = df_obs_merge[\n",
    "                (df_obs_merge[\"semana_id\"] == semana) & (df_obs_merge[\"riesgo_id\"] == riesgo)\n",
    "            ]\n",
    "            if not row_obs.empty:\n",
    "                n_opg_pos = int(row_obs[\"n_OPG_OPG+\"].iloc[0])\n",
    "                n_opg_neg = int(row_obs[\"n_OPG_OPG-\"].iloc[0])\n",
    "                n_occ_pos = int(row_obs[\"n_OCC_OCC+\"].iloc[0])\n",
    "                n_occ_neg = int(row_obs[\"n_OCC_OCC-\"].iloc[0])\n",
    "            else:\n",
    "                n_opg_pos = n_opg_neg = n_occ_pos = n_occ_neg = 0\n",
    "\n",
    "            # Auditorías\n",
    "            row_aud = df_aud_agg[\n",
    "                (df_aud_agg[\"semana_id\"] == semana) & (df_aud_agg[\"riesgo_id\"] == riesgo)\n",
    "            ]\n",
    "            n_auf = int(row_aud[\"n_auf\"].iloc[0]) if not row_aud.empty else 0\n",
    "\n",
    "            # FDO contexto semanal\n",
    "            row_fdo = df_fdo_sem[df_fdo_sem[\"semana_id\"] == semana].iloc[0]\n",
    "            fdo_contexto = float(row_fdo[\"fdo_contexto\"])\n",
    "\n",
    "            registros.append({\n",
    "                \"semana_id\": semana,\n",
    "                \"riesgo_id\": riesgo,\n",
    "                \"criticidad_stde\": float(criticidad),\n",
    "                \"n_hazard\": n_hazard,\n",
    "                \"n_nms\": n_nms,\n",
    "                \"n_imen\": n_imen,\n",
    "                \"n_opg_pos\": n_opg_pos,\n",
    "                \"n_opg_neg\": n_opg_neg,\n",
    "                \"n_occ_pos\": n_occ_pos,\n",
    "                \"n_occ_neg\": n_occ_neg,\n",
    "                \"n_auf\": n_auf,\n",
    "                \"fdo_contexto\": fdo_contexto,\n",
    "            })\n",
    "\n",
    "    df_senales = pd.DataFrame(registros)\n",
    "    return df_senales\n",
    "\n",
    "\n",
    "df_senales_k9 = construir_senales_riesgo_semana(\n",
    "    df_trayectorias,\n",
    "    df_eventos,\n",
    "    df_observaciones,\n",
    "    df_auditorias,\n",
    "    df_fdo_diario,\n",
    ")\n",
    "\n",
    "print(\"Señales K9 por riesgo/semana:\", df_senales_k9.shape)\n",
    "df_senales_k9.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf2403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.5 – Índice K9 (zona amarilla/roja + tendencia por riesgo y semana)\n",
    "\n",
    "def normalizar_columna(df, col):\n",
    "    max_val = df[col].max()\n",
    "    if max_val is None or max_val == 0:\n",
    "        return np.zeros(len(df))\n",
    "    return df[col] / max_val\n",
    "\n",
    "\n",
    "def construir_indice_k9(df_senales):\n",
    "    df = df_senales.copy()\n",
    "\n",
    "    # Normalización 0–1 de features\n",
    "    df[\"criticidad_norm\"] = normalizar_columna(df, \"criticidad_stde\")\n",
    "    df[\"n_nms_norm\"]      = normalizar_columna(df, \"n_nms\")\n",
    "    df[\"n_imen_norm\"]     = normalizar_columna(df, \"n_imen\")\n",
    "    df[\"n_occ_neg_norm\"]  = normalizar_columna(df, \"n_occ_neg\")\n",
    "    df[\"n_opg_neg_norm\"]  = normalizar_columna(df, \"n_opg_neg\")\n",
    "    df[\"n_auf_norm\"]      = normalizar_columna(df, \"n_auf\")\n",
    "\n",
    "    # Índice K9: combinación ponderada (señales de degradación)\n",
    "    df[\"indice_k9\"] = (\n",
    "        0.35 * df[\"criticidad_norm\"]\n",
    "        + 0.25 * df[\"n_nms_norm\"]\n",
    "        + 0.15 * df[\"n_imen_norm\"]\n",
    "        + 0.15 * df[\"n_occ_neg_norm\"]\n",
    "        + 0.05 * df[\"n_opg_neg_norm\"]\n",
    "        + 0.05 * df[\"n_auf_norm\"]\n",
    "    )\n",
    "\n",
    "    # Zona K9 (sin zona “verde”; usamos NORMAL como base)\n",
    "    thr_amarilla = 0.55\n",
    "    thr_roja     = 0.75\n",
    "\n",
    "    def clasificar_zona(val):\n",
    "        if val >= thr_roja:\n",
    "            return \"roja\"\n",
    "        elif val >= thr_amarilla:\n",
    "            return \"amarilla\"\n",
    "        else:\n",
    "            return \"normal\"\n",
    "\n",
    "    df[\"zona_k9\"] = df[\"indice_k9\"].apply(clasificar_zona)\n",
    "\n",
    "    # Tendencia (comparación semana a semana por riesgo)\n",
    "    df = df.sort_values([\"riesgo_id\", \"semana_id\"]).reset_index(drop=True)\n",
    "    df[\"delta_indice\"] = 0.0\n",
    "    df[\"tendencia_k9\"] = \"estable\"\n",
    "\n",
    "    for riesgo in df[\"riesgo_id\"].unique():\n",
    "        mask = df[\"riesgo_id\"] == riesgo\n",
    "        idxs = df[mask].index.tolist()\n",
    "        for i in range(1, len(idxs)):\n",
    "            idx_prev = idxs[i - 1]\n",
    "            idx_curr = idxs[i]\n",
    "            delta = df.loc[idx_curr, \"indice_k9\"] - df.loc[idx_prev, \"indice_k9\"]\n",
    "            df.loc[idx_curr, \"delta_indice\"] = delta\n",
    "\n",
    "            if delta >= 0.10:\n",
    "                df.loc[idx_curr, \"tendencia_k9\"] = \"acelerada\"\n",
    "            elif 0.03 <= delta < 0.10:\n",
    "                df.loc[idx_curr, \"tendencia_k9\"] = \"ascendente_lenta\"\n",
    "            elif -0.03 < delta < 0.03:\n",
    "                df.loc[idx_curr, \"tendencia_k9\"] = \"estable\"\n",
    "            else:\n",
    "                df.loc[idx_curr, \"tendencia_k9\"] = \"descendente\"\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_k9 = construir_indice_k9(df_senales_k9)\n",
    "print(\"Índice K9 por riesgo/semana:\", df_k9.shape)\n",
    "df_k9.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43147dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6.6 – Comparar modelo proactivo vs STDE vs K9 por riesgo y semana\n",
    "\n",
    "# Partimos de df_proactivo_thresholds (ya calculado en 6.2)\n",
    "# y df_k9 con índice y zonas.\n",
    "\n",
    "# Aseguramos tipos compatibles\n",
    "df_k9_compare = df_k9.rename(columns={\"semana_id\": \"semana_id\", \"riesgo_id\": \"riesgo_id\"})\n",
    "\n",
    "df_compare_full = df_proactivo_thresholds.merge(\n",
    "    df_k9_compare,\n",
    "    on=[\"semana_id\", \"riesgo_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Nos quedamos con los riesgos modelados en STDE v3\n",
    "df_compare_full = df_compare_full[df_compare_full[\"riesgo_id\"].isin(RIESGOS_FOCO)]\n",
    "\n",
    "# Orden lógico para análisis\n",
    "df_compare_full = df_compare_full.sort_values([\"semana_id\", \"riesgo_id\"])\n",
    "\n",
    "print(\"Comparación Proactivo vs K9:\", df_compare_full.shape)\n",
    "df_compare_full.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9652f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7.1 – Identificación del outlier del lunes crítico\n",
    "\n",
    "def detectar_outlier_lunes_critico(df_k9, df_eventos):\n",
    "    \"\"\"\n",
    "    Detecta señales previas al lunes crítico y compara con el evento real.\n",
    "    Devuelve un diccionario con la interpretación K9.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Detectar la fecha del lunes crítico\n",
    "    df_lc = df_eventos[df_eventos[\"es_lunes_critico\"] == True]\n",
    "    fecha_lc = df_lc[\"fecha\"].iloc[0]\n",
    "    semana_lc = df_lc[\"semana\"].iloc[0]\n",
    "\n",
    "    # 2) Filtrar trayectoria K9 previa para R01\n",
    "    df_r01 = df_k9[df_k9[\"riesgo_id\"] == \"R01\"]\n",
    "    df_r01_prev = df_r01[df_r01[\"semana_id\"] < semana_lc]\n",
    "\n",
    "    # 3) Señales previas\n",
    "    zona_prev = df_r01_prev[\"zona_k9\"].tolist()\n",
    "    tendencia_prev = df_r01_prev[\"tendencia_k9\"].tolist()\n",
    "    indice_prev = df_r01_prev[\"indice_k9\"].tolist()\n",
    "\n",
    "    outlier_info = {\n",
    "        \"fecha_lc\": fecha_lc,\n",
    "        \"semana_lc\": int(semana_lc),\n",
    "        \"zona_prev\": zona_prev,\n",
    "        \"tendencia_prev\": tendencia_prev,\n",
    "        \"indice_prev\": indice_prev,\n",
    "        \"n_eventos_lc\": df_lc.shape[0],\n",
    "        \"riesgos_lc\": df_lc[\"riesgo_id\"].unique().tolist(),\n",
    "    }\n",
    "\n",
    "    return outlier_info\n",
    "\n",
    "\n",
    "outlier_info = detectar_outlier_lunes_critico(df_k9, df_eventos)\n",
    "outlier_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08117e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7.2 – Ajuste conceptual del índice K9 post lunes crítico\n",
    "\n",
    "def recalibrar_k9(outlier_info, df_k9):\n",
    "    \"\"\"\n",
    "    Define nuevos thresholds y pesos internos para el índice K9.\n",
    "    No altera datos históricos: solo define parámetros futuros.\n",
    "    \"\"\"\n",
    "\n",
    "    # Thresholds originales\n",
    "    T_yellow = 0.55\n",
    "    T_red = 0.75\n",
    "\n",
    "    # Señales observadas previamente\n",
    "    prev_zonas = outlier_info[\"zona_prev\"]\n",
    "    prev_tendencias = outlier_info[\"tendencia_prev\"]\n",
    "\n",
    "    # ¿Había señales previas débiles?\n",
    "    senales_previas = any(z == \"amarilla\" for z in prev_zonas) or \\\n",
    "                      any(t in [\"ascendente_lenta\", \"acelerada\"] for t in prev_tendencias)\n",
    "\n",
    "    # Ajuste de thresholds\n",
    "    if senales_previas:\n",
    "        # K9 se vuelve más estricto\n",
    "        T_yellow_new = max(0.45, T_yellow - 0.05)\n",
    "        T_red_new = max(0.65, T_red - 0.05)\n",
    "    else:\n",
    "        T_yellow_new = T_yellow\n",
    "        T_red_new = T_red\n",
    "\n",
    "    # Ajuste de pesos internos\n",
    "    pesos_k9_new = {\n",
    "        \"w_criticidad\": 0.30,\n",
    "        \"w_nms\": 0.30,        # más peso a near miss\n",
    "        \"w_imen\": 0.15,\n",
    "        \"w_occ_neg\": 0.20,    # más sensibilidad a OCC-\n",
    "        \"w_opg_neg\": 0.03,\n",
    "        \"w_auf\": 0.02\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"T_yellow_new\": T_yellow_new,\n",
    "        \"T_red_new\": T_red_new,\n",
    "        \"pesos_k9_new\": pesos_k9_new\n",
    "    }\n",
    "\n",
    "\n",
    "ajuste_k9 = recalibrar_k9(outlier_info, df_k9)\n",
    "ajuste_k9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f659448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7.2 – Ajuste conceptual del índice K9 post lunes crítico\n",
    "\n",
    "def recalibrar_k9(outlier_info, df_k9):\n",
    "    \"\"\"\n",
    "    Define nuevos thresholds y pesos internos para el índice K9.\n",
    "    No altera datos históricos: solo define parámetros futuros.\n",
    "    \"\"\"\n",
    "\n",
    "    # Thresholds originales\n",
    "    T_yellow = 0.55\n",
    "    T_red = 0.75\n",
    "\n",
    "    # Señales observadas previamente\n",
    "    prev_zonas = outlier_info[\"zona_prev\"]\n",
    "    prev_tendencias = outlier_info[\"tendencia_prev\"]\n",
    "\n",
    "    # ¿Había señales previas débiles?\n",
    "    senales_previas = any(z == \"amarilla\" for z in prev_zonas) or \\\n",
    "                      any(t in [\"ascendente_lenta\", \"acelerada\"] for t in prev_tendencias)\n",
    "\n",
    "    # Ajuste de thresholds\n",
    "    if senales_previas:\n",
    "        # K9 se vuelve más estricto\n",
    "        T_yellow_new = max(0.45, T_yellow - 0.05)\n",
    "        T_red_new = max(0.65, T_red - 0.05)\n",
    "    else:\n",
    "        T_yellow_new = T_yellow\n",
    "        T_red_new = T_red\n",
    "\n",
    "    # Ajuste de pesos internos\n",
    "    pesos_k9_new = {\n",
    "        \"w_criticidad\": 0.30,\n",
    "        \"w_nms\": 0.30,        # más peso a near miss\n",
    "        \"w_imen\": 0.15,\n",
    "        \"w_occ_neg\": 0.20,    # más sensibilidad a OCC-\n",
    "        \"w_opg_neg\": 0.03,\n",
    "        \"w_auf\": 0.02\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"T_yellow_new\": T_yellow_new,\n",
    "        \"T_red_new\": T_red_new,\n",
    "        \"pesos_k9_new\": pesos_k9_new\n",
    "    }\n",
    "\n",
    "\n",
    "ajuste_k9 = recalibrar_k9(outlier_info, df_k9)\n",
    "ajuste_k9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b8d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7.3 – Reporte narrativo para la demo (K9 recalibration log)\n",
    "\n",
    "def generar_reporte_k9(outlier_info, ajuste_k9):\n",
    "    fecha = outlier_info[\"fecha_lc\"]\n",
    "    semana = outlier_info[\"semana_lc\"]\n",
    "    riesgos = \", \".join(outlier_info[\"riesgos_lc\"])\n",
    "\n",
    "    rep = f\"\"\"\n",
    "K9 RE-CALIBRATION REPORT – Lunes Crítico ({fecha}, semana {semana})\n",
    "\n",
    "1. Resumen del evento:\n",
    "   - Evento compuesto de riesgo(s): {riesgos}\n",
    "   - Near Miss severo activando control crítico.\n",
    "   - Evento fuera de la predicción del modelo proactivo.\n",
    "\n",
    "2. Señales previas detectadas por K9:\n",
    "   - Zonas previas: {outlier_info['zona_prev']}\n",
    "   - Tendencias previas: {outlier_info['tendencia_prev']}\n",
    "   - Índice previo: {outlier_info['indice_prev']}\n",
    "\n",
    "3. Interpretación:\n",
    "   K9 identifica señales emergentes no capturadas por el modelo proactivo,\n",
    "   incluyendo tendencias ascendentes y señales amarillas persistentes.\n",
    "   El lunes crítico confirma la subestimación del riesgo.\n",
    "\n",
    "4. Ajuste del modelo K9 para ciclos futuros:\n",
    "   - Nuevo threshold amarillo: {ajuste_k9['T_yellow_new']}\n",
    "   - Nuevo threshold rojo: {ajuste_k9['T_red_new']}\n",
    "   - Ajuste de pesos internos:\n",
    "     {ajuste_k9['pesos_k9_new']}\n",
    "\n",
    "5. Conclusión:\n",
    "   De presentarse un patrón similar en el futuro, K9 lo clasificará \n",
    "   anticipadamente en zona crítica, incluso si el ranking proactivo \n",
    "   lo mantiene fuera del Top 3.\n",
    "\"\"\"\n",
    "    return rep\n",
    "\n",
    "\n",
    "print(generar_reporte_k9(outlier_info, ajuste_k9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b2846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8.1 – Exportación de datasets STDE v3 a CSV\n",
    "\n",
    "# Trayectorias diarias y semanales\n",
    "df_trayectorias.to_csv(os.path.join(OUTPUT_DIR, \"stde_trayectorias_diarias.csv\"), index=False)\n",
    "df_trayectorias_semana.to_csv(os.path.join(OUTPUT_DIR, \"stde_trayectorias_semana.csv\"), index=False)\n",
    "\n",
    "# FDO\n",
    "df_fdo_diario.to_csv(os.path.join(OUTPUT_DIR, \"stde_fdo_diario.csv\"), index=False)\n",
    "\n",
    "# Eventos, observaciones, auditorías\n",
    "df_eventos.to_csv(os.path.join(OUTPUT_DIR, \"stde_eventos.csv\"), index=False)\n",
    "df_observaciones.to_csv(os.path.join(OUTPUT_DIR, \"stde_observaciones.csv\"), index=False)\n",
    "df_auditorias.to_csv(os.path.join(OUTPUT_DIR, \"stde_auditorias.csv\"), index=False)\n",
    "\n",
    "# Modelo proactivo + thresholds\n",
    "df_proactivo_thresholds.to_csv(\n",
    "    os.path.join(OUTPUT_DIR, \"stde_proactivo_semanal_v4_4_thresholds.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Señales K9 + índice\n",
    "df_k9.to_csv(os.path.join(OUTPUT_DIR, \"stde_senales_k9.csv\"), index=False)\n",
    "\n",
    "print(\"Archivos exportados en:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad02486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8.2 – Checks de consistencia STDE v3\n",
    "\n",
    "def check_ids_existentes(df, col, df_catalogo, col_id, nombre):\n",
    "    ids_df = set(df[col].dropna().unique())\n",
    "    ids_cat = set(df_catalogo[col_id].dropna().unique())\n",
    "    faltantes = ids_df - ids_cat\n",
    "    if faltantes:\n",
    "        print(f\"[ALERTA] {nombre}: IDs no encontrados en catálogo:\", faltantes)\n",
    "    else:\n",
    "        print(f\"[OK] {nombre}: todos los IDs existen en el catálogo.\")\n",
    "\n",
    "\n",
    "print(\"=== Checks de riesgos / roles / tareas / áreas ===\")\n",
    "check_ids_existentes(df_eventos, \"riesgo_id\", df_riesgos, \"id_riesgo\", \"Riesgos en eventos\")\n",
    "check_ids_existentes(df_observaciones, \"riesgo_id\", df_riesgos, \"id_riesgo\", \"Riesgos en observaciones\")\n",
    "check_ids_existentes(df_eventos, \"id_area\", df_areas, \"id_area\", \"Áreas en eventos\")\n",
    "check_ids_existentes(df_observaciones, \"id_area\", df_areas, \"id_area\", \"Áreas en observaciones\")\n",
    "\n",
    "print(\"\\n=== Lunes crítico ===\")\n",
    "df_lc = df_eventos[df_eventos[\"es_lunes_critico\"] == True]\n",
    "print(\"Eventos lunes crítico:\", df_lc.shape[0])\n",
    "print(df_lc[[\"id_evento\", \"riesgo_id\", \"tipo_narrativo\"]])\n",
    "\n",
    "print(\"\\n=== Degradación relativa R02 vs R01/R03 (criticidad semanal media) ===\")\n",
    "print(df_trayectorias_semana[[\"semana\", \"criticidad_R01_media\", \"criticidad_R02_media\", \"criticidad_R03_media\"]])\n",
    "\n",
    "print(\"\\n=== Observaciones por área (rangos generales) ===\")\n",
    "print(df_observaciones.groupby(\"id_area\")[\"id_observacion\"].count())\n",
    "\n",
    "print(\"\\n=== AUF reactivas vs OCC- / NMS ===\")\n",
    "print(\"Total AUF reactivas:\", df_auf_reactivas.shape[0])\n",
    "print(\"Total OCC-:\", df_observaciones[(df_observaciones['tipo_observacion']=='OCC') & (df_observaciones['estado']=='OCC-')].shape[0])\n",
    "print(\"Total NMS:\", df_eventos[df_eventos['tipo_narrativo']=='NMS'].shape[0])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
